{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to build a graph purely with KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.649 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='/media/HDD2/Datasets/mini_nusc', verbose=True)\n",
    "\n",
    "# nusc = NuScenes(version='v1.0-trainval', dataroot='/media/HDD2/Datasets/nuscenes2', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/maximilian/.cache/pyg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric as tgeo\n",
    "\n",
    "tgeo.get_home_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get set of scenes\n",
    "# scenes = nusc.scene\n",
    "# #Get first scenes\n",
    "# scene_0 = scenes[0]\n",
    "# # Get token of first frame\n",
    "# first_sample_token = scene_0['first_sample_token']\n",
    "\n",
    "# NUMBER_OF_SKIPPED_FRAMES = 10\n",
    "# for i in range(NUMBER_OF_SKIPPED_FRAMES):\n",
    "#     temp_sample = nusc.get('sample', first_sample_token)\n",
    "#     temp_token = temp_sample['next']\n",
    "#     first_sample_token = temp_token\n",
    "\n",
    "# sample_0 = nusc.get('sample', first_sample_token)\n",
    "# # Get tokens for 2 following frames\n",
    "# second_sample_token = sample_0['next']\n",
    "# sample_1 = nusc.get('sample', second_sample_token)\n",
    "# third_sample_token = sample_1['next']\n",
    "# sample_2 = nusc.get('sample', third_sample_token)\n",
    "\n",
    "# # Get LIDAR pointcloud\n",
    "# sensor = 'LIDAR_TOP'\n",
    "# lidar_top_data_0 = nusc.get('sample_data', sample_0['data'][sensor])\n",
    "# # Get LIDAR KF pointcloud\n",
    "# lidar_top_data_1 = nusc.get('sample_data', sample_1['data'][sensor])\n",
    "# # Get LIDAR KF pointcloud\n",
    "# lidar_top_data_2 = nusc.get('sample_data', sample_2['data'][sensor])\n",
    "\n",
    "# #Filter out car/vehicle object\n",
    "# pcl0_path, boxes0, _= nusc.get_sample_data(lidar_top_data_0['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "# pcl1_path, boxes1, _= nusc.get_sample_data(lidar_top_data_1['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "# pcl2_path, boxes2, _= nusc.get_sample_data(lidar_top_data_2['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get point clouds\n",
    "# import os.path as osp\n",
    "# from nuscenes.utils.data_classes import LidarPointCloud, Box\n",
    "\n",
    "# #Load Pointclouds\n",
    "# pc0 = LidarPointCloud.from_file(pcl0_path)\n",
    "# pc1 = LidarPointCloud.from_file(pcl1_path)\n",
    "# pc2 = LidarPointCloud.from_file(pcl2_path)\n",
    "\n",
    "# from utility import get_box_centers, filter_boxes\n",
    "\n",
    "# car_boxes_0 = filter_boxes(nusc, boxes = boxes0, categoryQuery= 'vehicle.car')\n",
    "# car_boxes_1 = filter_boxes(nusc, boxes = boxes1, categoryQuery= 'vehicle.car')\n",
    "# car_boxes_2 = filter_boxes(nusc, boxes = boxes2, categoryQuery= 'vehicle.car')\n",
    "\n",
    "# centers0 = get_box_centers(car_boxes_0)\n",
    "# centers1 = get_box_centers(car_boxes_1)\n",
    "# centers2 = get_box_centers(car_boxes_2)\n",
    "\n",
    "# # Special Shift parameter in meter\n",
    "# SPATIAL_SHIFT_TIMEFRAMES = 20\n",
    "# # Boxes 0 can stay at the current frame\n",
    "# # centers0\n",
    "# # Boxes 1 must be translated up by l meters\n",
    "# centers1 += np.array([0,0,SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# # Boxes 2 must be translated up by 2*l meters\n",
    "# centers2 += np.array([0,0,2*SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# # Add all centroids into one array\n",
    "# centers = np.empty((0,3))\n",
    "# centers = np.append(centers, centers0, axis=0)\n",
    "# centers = np.append(centers, centers1, axis=0)\n",
    "# centers = np.append(centers, centers2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build KNN Graph\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from graph.graph_generation import Graph\n",
    "\n",
    "# # Add temporal edges / Make connections#####################\n",
    "# temporal_pointpairs = []\n",
    "\n",
    "# TEMPORAL_KNN_PARAM = 3\n",
    "# ''' \n",
    "# Defines the number of searched neighbors\n",
    "# '''\n",
    "\n",
    "# # connect frame-0-nodes with frame-1-nodes\n",
    "# for i in range(len(centers0)):\n",
    "#     center = centers0[i]\n",
    "#     center = np.expand_dims(center,axis=0)\n",
    "#     temp = np.append(centers1,center,axis=0)\n",
    "#     #Find nearest_neigbor\n",
    "#     nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "#     temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "#     #Add indices into a list\n",
    "#     for index in temporal_indices[-1]:\n",
    "#         #adapt the index to the global indexing\n",
    "#         # temporal_pointpairs.append([i, index + len(centers0)])\n",
    "\n",
    "#         # find global indices and append them\n",
    "#         reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "#         neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "#         temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "#              neighbor_node_global_index ])\n",
    "\n",
    "# # connect frame-0-nodes with frame-2-nodes\n",
    "# for i in range(len(centers0)):\n",
    "#     center = centers0[i]\n",
    "#     center = np.expand_dims(center,axis=0)\n",
    "#     temp = np.append(centers2,center,axis=0)\n",
    "#     #Find nearest_neigbor\n",
    "#     nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "#     temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "#     #Add indices into a list (The last entry belongs to center!)\n",
    "#     for index in temporal_indices[-1]:\n",
    "#         #adapt the index to the global indexing\n",
    "#         # temporal_pointpairs.append([i, index + len(centers0)])\n",
    "\n",
    "#         # find global indices and append them\n",
    "#         reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "#         neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "#         temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "#              neighbor_node_global_index ])\n",
    "\n",
    "# # connect frame-1-nodes with frame-2-nodes\n",
    "# for i in range(len(centers1)):\n",
    "#     center = centers1[i]\n",
    "#     center = np.expand_dims(center,axis=0)\n",
    "#     temp = np.append(centers2,center,axis=0)\n",
    "#     nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "#     temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "\n",
    "#     # Test if the last input is the appended center point\n",
    "#     # assert (temporal_distances[-1] == temporal_distances[np.argwhere(temp == center)[0,0]]).all()\n",
    "\n",
    "#     for index in temporal_indices[-1]:\n",
    "#         #adapt the index to the global indexing\n",
    "#         # temporal_pointpairs.append([i + len(centers0) , index + len(centers0) + len(centers1) ])\n",
    "        \n",
    "#         # find global indices and append them\n",
    "#         reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "#         neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "#         temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "#              neighbor_node_global_index ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Build graph in a more organised manner\n",
    "# from graph.graph_generation import SpatioTemporalGraph, Timeframe\n",
    "\n",
    "# SPATIAL_NEIGHBOR_NUMS = 5\n",
    "\n",
    "# nbrs_0 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers0)\n",
    "# # Frame t0\n",
    "# #Compute K nearest neighbors\n",
    "# spatial_distances_0, spatial_indices_0 = nbrs_0.kneighbors(centers0)\n",
    "# # Make a list of tuple pairs\n",
    "# spatial_pairs = [] \n",
    "# for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_0):\n",
    "#     for neigbor_index in neigborhood_indices:\n",
    "#         spatial_pairs.append( \\\n",
    "#             ( (Timeframe.t0,curr_node_idx) , ((Timeframe.t0,neigbor_index)) ) )\n",
    "\n",
    "# #Frame t1\n",
    "# nbrs_1 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers1)\n",
    "# spatial_distances_1, spatial_indices_1 = nbrs_1.kneighbors(centers1)\n",
    "# # Make a list of tuple pairs\n",
    "# for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_1):\n",
    "#     for neigbor_index in neigborhood_indices:\n",
    "#         spatial_pairs.append( \\\n",
    "#             ( (Timeframe.t1,curr_node_idx) , ((Timeframe.t1,neigbor_index)) ) )\n",
    "\n",
    "# #Frame t2\n",
    "# nbrs_2 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers2)\n",
    "# spatial_distances_2, spatial_indices_2 = nbrs_2.kneighbors(centers2)\n",
    "# # Make a list of tuple pairs\n",
    "# for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_2):\n",
    "#     for neigbor_index in neigborhood_indices:\n",
    "#         spatial_pairs.append( \\\n",
    "#             ( (Timeframe.t2,curr_node_idx) , ((Timeframe.t2,neigbor_index)) ) )\n",
    "\n",
    "# testgraph = SpatioTemporalGraph(spatial_pairs)\n",
    "\n",
    "# # Get all spatial Edges\n",
    "# spatial_pointpairs0 = []\n",
    "# for reference_node in testgraph._graph:\n",
    "#     if(reference_node[0]== Timeframe.t0):\n",
    "#         for neighbor_node in testgraph._graph[reference_node]:\n",
    "#             # print(neighbor_index[0])\n",
    "#             timestep, idx = neighbor_node[0],neighbor_node[1]\n",
    "#             if timestep == Timeframe.t0:\n",
    "#                 spatial_pointpairs0.append([reference_node[1],idx])\n",
    "\n",
    "# print(np.shape(spatial_pointpairs0))\n",
    "# testarray = testgraph.get_spatial_pointpairs(Timeframe.t0)\n",
    "# assert spatial_pointpairs0 == testarray\n",
    "\n",
    "# spatial_pointpairs1 = testgraph.get_spatial_pointpairs(Timeframe.t1)\n",
    "# spatial_pointpairs2 = testgraph.get_spatial_pointpairs(Timeframe.t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate  Flow Labels for TrackingGNN\n",
    "# from groundtruth_generation.nuscenes_create_gt import generate_flow_labels\n",
    "# from utils.nuscenes_helper_functions import is_valid_box\n",
    "\n",
    "# car_boxes = [] \n",
    "# for list in [car_boxes_0, car_boxes_1, car_boxes_2]:\n",
    "#     for box in list:\n",
    "#         car_boxes.append(box)\n",
    "\n",
    "# if len(car_boxes)== len(centers):\n",
    "#     print('length', len(car_boxes))\n",
    "#     # for box, center in zip(car_boxes, centers):\n",
    "#     for i in range(len(car_boxes)):\n",
    "#         box, center = car_boxes[i], centers[i]\n",
    "#         if not is_valid_box(box, center, num_frames = 3, spatial_shift_timeframes=SPATIAL_SHIFT_TIMEFRAMES):\n",
    "#             print('invalid boxes at ',i)\n",
    "#             print('box',box.center)\n",
    "#             print('center',center)\n",
    "\n",
    "# flow_labels = generate_flow_labels(nusc,temporal_pointpairs, car_boxes, centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.loader import DataLoader\n",
    "# import torch\n",
    "# edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "#                            [1, 0, 2, 1]], dtype=torch.long)\n",
    "# x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "# data = Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create list of Data elements\n",
    "# # \n",
    "# data_list = []\n",
    "# spatio_temporal_edge_indices = temporal_pointpairs \\\n",
    "#         + spatial_pointpairs0\n",
    "\n",
    "# data_list.append(Data(x= centers,edge_index= spatio_temporal_edge_indices, y= flow_labels))\n",
    "\n",
    "# standard_loader = DataLoader(data_list, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train import start_training\n",
    "\n",
    "# batch_size = 1\n",
    "# num_epochs = 5\n",
    "# start_training(standard_loader, batch_size, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import start_training\n",
    "from datasets.nuscenes_dataset import NuscenesDataset\n",
    "\n",
    "# train_dataset = NuscenesDataset()\n",
    "# batch_size = 1\n",
    "# num_epochs = 5\n",
    "# start_training(train_dataset, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'test', 'mini_train', 'mini_val', 'train_detect', 'train_track'])\n"
     ]
    }
   ],
   "source": [
    "from nuscenes.utils.splits import train,val\n",
    "from nuscenes.utils.splits import create_splits_scenes\n",
    "\n",
    "split = create_splits_scenes()\n",
    "print(split.keys())\n",
    "split_scene_list = []\n",
    "for scene_name in split['mini_train']:\n",
    "    for scene in nusc.scene:\n",
    "        if scene['name']==scene_name:\n",
    "            split_scene_list.append(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n",
      "('cc8c0bf57f984915a77078b10eb33198', 'ca9a282c9e77460f8360f564131a8af5')\n",
      "('cc8c0bf57f984915a77078b10eb33198', '39586f9d59004284a7114a68825e8eec')\n",
      "('cc8c0bf57f984915a77078b10eb33198', '356d81f38dd9473ba590f39e266f54e5')\n"
     ]
    }
   ],
   "source": [
    "#write a sequence \n",
    "\n",
    "sample_dict = {}\n",
    "\n",
    "i = 0 \n",
    "for scene in split_scene_list:\n",
    "    last_sample_token =\"\"\n",
    "    sample_token = scene['first_sample_token']\n",
    "    while(last_sample_token == \"\"):\n",
    "        \n",
    "        sample = nusc.get('sample', sample_token)\n",
    "        sample_dict[i] = (scene['token'],sample[\"token\"])\n",
    "        i += 1\n",
    "        sample_token = sample[\"next\"]\n",
    "        if(sample[\"token\"]== scene['last_sample_token']):\n",
    "            last_sample_token = scene['last_sample_token']\n",
    "\n",
    "print (len(sample_dict))\n",
    "print (sample_dict[0])\n",
    "print (sample_dict[1])\n",
    "print (sample_dict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5638, 0.4236, 0.3750, 0.8855],\n",
      "        [0.2826, 0.2367, 0.2039, 0.9313],\n",
      "        [0.6879, 0.6946, 0.6231, 0.0440]]) \n",
      " tensor([[ True, False,  True,  True],\n",
      "        [False, False, False, False],\n",
      "        [ True,  True,  True, False]])\n",
      "tensor([0.5638, 0.3750, 0.8855, 0.6879, 0.6946, 0.6231])\n",
      "tensor([0.5638, 0.3750, 0.8855, 0.6879, 0.6946, 0.6231])\n",
      "tensor([[1, 0, 1, 1],\n",
      "        [0, 0, 0, 0],\n",
      "        [1, 1, 1, 0]])\n",
      "y: tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]])\n",
      "y_onehot: tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# # setting device on GPU if available, else CPU\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print('Using device:', device)\n",
    "\n",
    "# #Additional Info when using cuda\n",
    "# if device.type == 'cuda':\n",
    "#     print(torch.cuda.is_available())\n",
    "#     num_gpu = torch.cuda.device_count()\n",
    "#     print(\"num_gpu:\",num_gpu)\n",
    "#     print(\"current_device: \",torch.cuda.current_device())\n",
    "#     print(\"---------------------------------------------------------------\")\n",
    "#     for i in range(num_gpu):\n",
    "#         print(torch.cuda.get_device_name(i))\n",
    "#         # print(torch.cuda.device(i))\n",
    "#         print('Memory Usage:')\n",
    "#         print('Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB', torch.cuda.memory_allocated(i),torch.cuda.memory_allocated(i)/1024**3)\n",
    "#         print('Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB', torch.cuda.memory_reserved(i),torch.cuda.memory_reserved(i)/1024**3)\n",
    "#         print(\"---------------------------------------------------------------\")\n",
    "\n",
    "a = torch.rand((3,4))\n",
    "b = torch.rand_like(a).ge(0.5)\n",
    "\n",
    "print(a,\"\\n\", b)\n",
    "print(a[b])\n",
    "print(a.masked_select(b))\n",
    "\n",
    "print(torch.where(b==True,1,0))\n",
    "\n",
    "from enum import IntEnum\n",
    "class edge_types(IntEnum):\n",
    "    spatial_edges = 0\n",
    "    temporal_edges = 1\n",
    "\n",
    "y = torch.LongTensor(4,1).random_() % 2\n",
    "print(\"y:\", y)\n",
    "y_onehot = torch.FloatTensor(4, 2)\n",
    "y_onehot.zero_()\n",
    "y_onehot.scatter_(1,y,1)\n",
    "print(\"y_onehot:\", y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'relative_vectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92569/3392931268.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mis_possible2construct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_possible2construct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_possible2construct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_graph_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# object.assign_edge_labels_one_hot()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_edge_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/spatio_temporal_graph/datasets/nuscenes_mot_graph.py\u001b[0m in \u001b[0;36mconstruct_graph_object\u001b[0;34m(self, edge_feature_mode)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Edge Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0medge_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_feats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'relative_vectors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;31m# Transpose if not Graph connectivity in COO format with shape :obj:`[2, num_edges]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt_edge_ixs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'relative_vectors'"
     ]
    }
   ],
   "source": [
    "#Create List of Graph objects\n",
    "from datasets.nuscenes_mot_graph import NuscenesMotGraph\n",
    "#______________________________________________________________#\n",
    "# Decide if only first scene should be computed\n",
    "only_first_scene = True\n",
    "scene_token0, sample_token0= sample_dict[0]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        if torch.cuda.get_device_name(i) == \"GeForce RTX 2080\":\n",
    "            device = torch.device(i) # RTX 2080 8GB\n",
    "print(\"Device:\", device)\n",
    "#_______________________________________________________________#\n",
    "\n",
    "MotGraphList= []\n",
    "for sample_key in sample_dict:\n",
    "    scene_token_current, sample_token_current= sample_dict[sample_key]\n",
    "    if(only_first_scene):\n",
    "        if(scene_token0 == scene_token_current):\n",
    "            object = NuscenesMotGraph(nuscenes_handle = nusc,\n",
    "                        start_frame=sample_token_current,\n",
    "                        max_frame_dist = 3, \n",
    "                        filterBoxes_categoryQuery='vehicle.car',\n",
    "                        device= device)\n",
    "            is_possible2construct = object.is_possible2construct\n",
    "            if is_possible2construct:\n",
    "                object.construct_graph_object()\n",
    "                # object.assign_edge_labels_one_hot()\n",
    "                object.assign_edge_labels(label_type='multiclass')\n",
    "                # object.assign_edge_labels(label_type='binary')\n",
    "                MotGraphList.append(object)\n",
    "    else:\n",
    "        object = NuscenesMotGraph(nuscenes_handle = nusc,\n",
    "                        start_frame=sample_token_current,\n",
    "                        max_frame_dist = 3,  \n",
    "                        filterBoxes_categoryQuery='vehicle.car',device= device)\n",
    "        is_possible2construct = object.is_possible2construct\n",
    "        if is_possible2construct:\n",
    "            object.construct_graph_object()\n",
    "            object.assign_edge_labels(label_type='binary')\n",
    "            MotGraphList.append(object)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input\n",
    "# print(\"----------------------------------------\\n\")\n",
    "# print(MotGraphList[0].graph_obj.keys)\n",
    "# print(\"----------------------------------------\\n\")\n",
    "# print(\"Node features: \", MotGraphList[0].graph_obj['x'])\n",
    "# print(\"----------------------------------------\\n\")\n",
    "# print(\"Edge indices\", MotGraphList[0].graph_obj['edge_index'])\n",
    "# print(\"----------------------------------------\\n\")\n",
    "# print(\"Edge attributes (only temporal until now)\", MotGraphList[0].graph_obj['edge_attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Output\n",
    "# from groundtruth_generation.nuscenes_create_gt import edge_label_classes\n",
    "\n",
    "# print(\"edge_label_classes.different_instance:\",edge_label_classes.different_instance)\n",
    "# print(\"edge_label_classes.same_instance:\",edge_label_classes.same_instance)\n",
    "# print(\"edge_label_classes.new_instance:\",edge_label_classes.new_instance)\n",
    "# print(\"Edge labels: one hot encoding\",MotGraphList[0].graph_obj[\"edge_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------------------------------\\n\")\n",
    "print(len(MotGraphList))\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0])\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj)\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(len(MotGraphList[0].graph_obj))\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj.keys)\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(\"is_undirected() : \",MotGraphList[0].graph_obj.is_undirected())\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj[\"x\"][0:5])\n",
    "\n",
    "print(\"----------------------------------------\\n\")\n",
    "print('graph_dataframe[\"boxes_dict\"][1][0] \\n',MotGraphList[0].graph_dataframe[\"boxes_dict\"][1][0])\n",
    "print(\"----------------------------------------\\n\")\n",
    "box_list, center_list = MotGraphList[0].graph_dataframe[\"centers_dict\"][1]\n",
    "print(\"box_list: \\n\",box_list[0], 'center_list: \\n', center_list[0])\n",
    "print(\"----------------------------------------\\n\")\n",
    "box_list, center_list = MotGraphList[0].graph_dataframe[\"centers_dict\"][1]\n",
    "print(\"is same memory ?: \\n\", MotGraphList[0].graph_dataframe[\"boxes_dict\"][1] is box_list )\n",
    "print(\"----------------------------------------\\n\")\n",
    "for i in range(3):\n",
    "    print(MotGraphList[0].graph_dataframe[\"boxes_list_all\"][i] )\n",
    "    print(MotGraphList[0].graph_dataframe[\"centers_list_all\"][i])\n",
    "    print(\"----------------------------------------\\n\")\n",
    "print(\"----------------------------------------\\n\")\n",
    "for i in range(3):\n",
    "    print(MotGraphList[0].graph_dataframe[\"boxes_list_all\"][-i] )\n",
    "    print(MotGraphList[0].graph_dataframe[\"centers_list_all\"][-i])\n",
    "    print(\"----------------------------------------\\n\")\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(\"Edge Labels: \",MotGraphList[0].graph_obj[\"edge_labels\"])\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(\"Edge Labels: \",MotGraphList[-1].graph_obj[\"edge_labels\"])\n",
    "print(\"----------------------------------------\\n\")\n",
    "\n",
    "print(\"shape: \",MotGraphList[0].graph_obj.x.shape)\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(\"Edge Labels: \",MotGraphList[0].graph_obj[\"edge_index\"])\n",
    "print(\"----------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(3, 16)\n",
    "        self.conv2 = GCNConv(16, 2)\n",
    "        self.mlp = torch.nn.Linear(\n",
    "                    in_features=3, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x \n",
    "        edge_index = data.edge_index\n",
    "        edge_feature =data.edge_attr\n",
    "\n",
    "        # x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        x = x.float()\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "graph_list = []\n",
    "for graph in MotGraphList:\n",
    "    graph_list.append(graph.graph_obj)\n",
    "print(len(graph_list))\n",
    "print(graph_list[:5])\n",
    "train_loader = DataLoader(graph_list, batch_size=1,shuffle =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in train_loader:\n",
    "    # print(data.x)\n",
    "    # print(data.edge_index)\n",
    "    # print(data.edge_attr)\n",
    "    # print(data.num_graphs)\n",
    "\n",
    "# a = torch.zeros(3,5).to('cuda')\n",
    "# probabilities_labels = torch.empty(a.shape).uniform_(0, 1).to('cuda')\n",
    "# label = torch.bernoulli(probabilities_labels).to('cuda')\n",
    "# print(a)\n",
    "# print(probabilities_labels)\n",
    "# print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def train():\n",
    "#     model.train()\n",
    "\n",
    "#     loss_all = 0\n",
    "#     for data in train_loader:\n",
    "#         data = data.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         label = data.y.to(device)\n",
    "#         loss = crit(output, label)\n",
    "#         loss.backward()\n",
    "#         loss_all += data.num_graphs * loss.item()\n",
    "#         optimizer.step()\n",
    "#     return loss_all / len(graph_list)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = Net().to(device)\n",
    "print(next(model.parameters()).is_cuda)\n",
    "# print(model.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "crit = torch.nn.BCELoss()\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "loss_general = []\n",
    "for epoch in range(4):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #Generate random labels for testing pipeline\n",
    "        # generate binary labels \n",
    "        probabilities_labels = torch.empty(output.shape).uniform_(0, 1).to(device)\n",
    "        node_labels_binary = torch.bernoulli(probabilities_labels)\n",
    "        loss = crit(output, node_labels_binary)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    loss_normalized =loss_all / len(graph_list)\n",
    "    loss_general.append(loss_normalized)\n",
    "    print('epoch',epoch,'loss_general:',loss_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "434941593aed7c9146eb321e17df2547a675a0813990b3197c9f49b3135b1bdb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
