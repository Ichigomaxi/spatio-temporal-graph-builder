{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to build a graph purely with KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.534 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='/media/HDD2/Datasets/mini_nusc', verbose=True)\n",
    "\n",
    "# nusc = NuScenes(version='v1.0-trainval', dataroot='/media/HDD2/Datasets/nuscenes2', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/maximilian/.cache/pyg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric as tgeo\n",
    "\n",
    "tgeo.get_home_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get set of scenes\n",
    "# scenes = nusc.scene\n",
    "# #Get first scenes\n",
    "# scene_0 = scenes[0]\n",
    "# # Get token of first frame\n",
    "# first_sample_token = scene_0['first_sample_token']\n",
    "\n",
    "# NUMBER_OF_SKIPPED_FRAMES = 10\n",
    "# for i in range(NUMBER_OF_SKIPPED_FRAMES):\n",
    "#     temp_sample = nusc.get('sample', first_sample_token)\n",
    "#     temp_token = temp_sample['next']\n",
    "#     first_sample_token = temp_token\n",
    "\n",
    "# sample_0 = nusc.get('sample', first_sample_token)\n",
    "# # Get tokens for 2 following frames\n",
    "# second_sample_token = sample_0['next']\n",
    "# sample_1 = nusc.get('sample', second_sample_token)\n",
    "# third_sample_token = sample_1['next']\n",
    "# sample_2 = nusc.get('sample', third_sample_token)\n",
    "\n",
    "# # Get LIDAR pointcloud\n",
    "# sensor = 'LIDAR_TOP'\n",
    "# lidar_top_data_0 = nusc.get('sample_data', sample_0['data'][sensor])\n",
    "# # Get LIDAR KF pointcloud\n",
    "# lidar_top_data_1 = nusc.get('sample_data', sample_1['data'][sensor])\n",
    "# # Get LIDAR KF pointcloud\n",
    "# lidar_top_data_2 = nusc.get('sample_data', sample_2['data'][sensor])\n",
    "\n",
    "# #Filter out car/vehicle object\n",
    "# pcl0_path, boxes0, _= nusc.get_sample_data(lidar_top_data_0['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "# pcl1_path, boxes1, _= nusc.get_sample_data(lidar_top_data_1['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "# pcl2_path, boxes2, _= nusc.get_sample_data(lidar_top_data_2['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get point clouds\n",
    "# import os.path as osp\n",
    "# from nuscenes.utils.data_classes import LidarPointCloud, Box\n",
    "\n",
    "# #Load Pointclouds\n",
    "# pc0 = LidarPointCloud.from_file(pcl0_path)\n",
    "# pc1 = LidarPointCloud.from_file(pcl1_path)\n",
    "# pc2 = LidarPointCloud.from_file(pcl2_path)\n",
    "\n",
    "# from utility import get_box_centers, filter_boxes\n",
    "\n",
    "# car_boxes_0 = filter_boxes(nusc, boxes = boxes0, categoryQuery= 'vehicle.car')\n",
    "# car_boxes_1 = filter_boxes(nusc, boxes = boxes1, categoryQuery= 'vehicle.car')\n",
    "# car_boxes_2 = filter_boxes(nusc, boxes = boxes2, categoryQuery= 'vehicle.car')\n",
    "\n",
    "# centers0 = get_box_centers(car_boxes_0)\n",
    "# centers1 = get_box_centers(car_boxes_1)\n",
    "# centers2 = get_box_centers(car_boxes_2)\n",
    "\n",
    "# # Special Shift parameter in meter\n",
    "# SPATIAL_SHIFT_TIMEFRAMES = 20\n",
    "# # Boxes 0 can stay at the current frame\n",
    "# # centers0\n",
    "# # Boxes 1 must be translated up by l meters\n",
    "# centers1 += np.array([0,0,SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# # Boxes 2 must be translated up by 2*l meters\n",
    "# centers2 += np.array([0,0,2*SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# # Add all centroids into one array\n",
    "# centers = np.empty((0,3))\n",
    "# centers = np.append(centers, centers0, axis=0)\n",
    "# centers = np.append(centers, centers1, axis=0)\n",
    "# centers = np.append(centers, centers2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build KNN Graph\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from graph.graph_generation import Graph\n",
    "\n",
    "# # Add temporal edges / Make connections#####################\n",
    "# temporal_pointpairs = []\n",
    "\n",
    "# TEMPORAL_KNN_PARAM = 3\n",
    "# ''' \n",
    "# Defines the number of searched neighbors\n",
    "# '''\n",
    "\n",
    "# # connect frame-0-nodes with frame-1-nodes\n",
    "# for i in range(len(centers0)):\n",
    "#     center = centers0[i]\n",
    "#     center = np.expand_dims(center,axis=0)\n",
    "#     temp = np.append(centers1,center,axis=0)\n",
    "#     #Find nearest_neigbor\n",
    "#     nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "#     temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "#     #Add indices into a list\n",
    "#     for index in temporal_indices[-1]:\n",
    "#         #adapt the index to the global indexing\n",
    "#         # temporal_pointpairs.append([i, index + len(centers0)])\n",
    "\n",
    "#         # find global indices and append them\n",
    "#         reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "#         neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "#         temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "#              neighbor_node_global_index ])\n",
    "\n",
    "# # connect frame-0-nodes with frame-2-nodes\n",
    "# for i in range(len(centers0)):\n",
    "#     center = centers0[i]\n",
    "#     center = np.expand_dims(center,axis=0)\n",
    "#     temp = np.append(centers2,center,axis=0)\n",
    "#     #Find nearest_neigbor\n",
    "#     nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "#     temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "#     #Add indices into a list (The last entry belongs to center!)\n",
    "#     for index in temporal_indices[-1]:\n",
    "#         #adapt the index to the global indexing\n",
    "#         # temporal_pointpairs.append([i, index + len(centers0)])\n",
    "\n",
    "#         # find global indices and append them\n",
    "#         reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "#         neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "#         temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "#              neighbor_node_global_index ])\n",
    "\n",
    "# # connect frame-1-nodes with frame-2-nodes\n",
    "# for i in range(len(centers1)):\n",
    "#     center = centers1[i]\n",
    "#     center = np.expand_dims(center,axis=0)\n",
    "#     temp = np.append(centers2,center,axis=0)\n",
    "#     nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "#     temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "\n",
    "#     # Test if the last input is the appended center point\n",
    "#     # assert (temporal_distances[-1] == temporal_distances[np.argwhere(temp == center)[0,0]]).all()\n",
    "\n",
    "#     for index in temporal_indices[-1]:\n",
    "#         #adapt the index to the global indexing\n",
    "#         # temporal_pointpairs.append([i + len(centers0) , index + len(centers0) + len(centers1) ])\n",
    "        \n",
    "#         # find global indices and append them\n",
    "#         reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "#         neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "#         temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "#              neighbor_node_global_index ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Build graph in a more organised manner\n",
    "# from graph.graph_generation import SpatioTemporalGraph, Timeframe\n",
    "\n",
    "# SPATIAL_NEIGHBOR_NUMS = 5\n",
    "\n",
    "# nbrs_0 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers0)\n",
    "# # Frame t0\n",
    "# #Compute K nearest neighbors\n",
    "# spatial_distances_0, spatial_indices_0 = nbrs_0.kneighbors(centers0)\n",
    "# # Make a list of tuple pairs\n",
    "# spatial_pairs = [] \n",
    "# for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_0):\n",
    "#     for neigbor_index in neigborhood_indices:\n",
    "#         spatial_pairs.append( \\\n",
    "#             ( (Timeframe.t0,curr_node_idx) , ((Timeframe.t0,neigbor_index)) ) )\n",
    "\n",
    "# #Frame t1\n",
    "# nbrs_1 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers1)\n",
    "# spatial_distances_1, spatial_indices_1 = nbrs_1.kneighbors(centers1)\n",
    "# # Make a list of tuple pairs\n",
    "# for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_1):\n",
    "#     for neigbor_index in neigborhood_indices:\n",
    "#         spatial_pairs.append( \\\n",
    "#             ( (Timeframe.t1,curr_node_idx) , ((Timeframe.t1,neigbor_index)) ) )\n",
    "\n",
    "# #Frame t2\n",
    "# nbrs_2 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers2)\n",
    "# spatial_distances_2, spatial_indices_2 = nbrs_2.kneighbors(centers2)\n",
    "# # Make a list of tuple pairs\n",
    "# for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_2):\n",
    "#     for neigbor_index in neigborhood_indices:\n",
    "#         spatial_pairs.append( \\\n",
    "#             ( (Timeframe.t2,curr_node_idx) , ((Timeframe.t2,neigbor_index)) ) )\n",
    "\n",
    "# testgraph = SpatioTemporalGraph(spatial_pairs)\n",
    "\n",
    "# # Get all spatial Edges\n",
    "# spatial_pointpairs0 = []\n",
    "# for reference_node in testgraph._graph:\n",
    "#     if(reference_node[0]== Timeframe.t0):\n",
    "#         for neighbor_node in testgraph._graph[reference_node]:\n",
    "#             # print(neighbor_index[0])\n",
    "#             timestep, idx = neighbor_node[0],neighbor_node[1]\n",
    "#             if timestep == Timeframe.t0:\n",
    "#                 spatial_pointpairs0.append([reference_node[1],idx])\n",
    "\n",
    "# print(np.shape(spatial_pointpairs0))\n",
    "# testarray = testgraph.get_spatial_pointpairs(Timeframe.t0)\n",
    "# assert spatial_pointpairs0 == testarray\n",
    "\n",
    "# spatial_pointpairs1 = testgraph.get_spatial_pointpairs(Timeframe.t1)\n",
    "# spatial_pointpairs2 = testgraph.get_spatial_pointpairs(Timeframe.t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate  Flow Labels for TrackingGNN\n",
    "# from groundtruth_generation.nuscenes_create_gt import generate_flow_labels\n",
    "# from utils.nuscenes_helper_functions import is_valid_box\n",
    "\n",
    "# car_boxes = [] \n",
    "# for list in [car_boxes_0, car_boxes_1, car_boxes_2]:\n",
    "#     for box in list:\n",
    "#         car_boxes.append(box)\n",
    "\n",
    "# if len(car_boxes)== len(centers):\n",
    "#     print('length', len(car_boxes))\n",
    "#     # for box, center in zip(car_boxes, centers):\n",
    "#     for i in range(len(car_boxes)):\n",
    "#         box, center = car_boxes[i], centers[i]\n",
    "#         if not is_valid_box(box, center, num_frames = 3, spatial_shift_timeframes=SPATIAL_SHIFT_TIMEFRAMES):\n",
    "#             print('invalid boxes at ',i)\n",
    "#             print('box',box.center)\n",
    "#             print('center',center)\n",
    "\n",
    "# flow_labels = generate_flow_labels(nusc,temporal_pointpairs, car_boxes, centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.loader import DataLoader\n",
    "# import torch\n",
    "# edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "#                            [1, 0, 2, 1]], dtype=torch.long)\n",
    "# x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "# data = Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create list of Data elements\n",
    "# # \n",
    "# data_list = []\n",
    "# spatio_temporal_edge_indices = temporal_pointpairs \\\n",
    "#         + spatial_pointpairs0\n",
    "\n",
    "# data_list.append(Data(x= centers,edge_index= spatio_temporal_edge_indices, y= flow_labels))\n",
    "\n",
    "# standard_loader = DataLoader(data_list, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train import start_training\n",
    "\n",
    "# batch_size = 1\n",
    "# num_epochs = 5\n",
    "# start_training(standard_loader, batch_size, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import start_training\n",
    "from datasets.nuscenes_dataset import NuscenesDataset\n",
    "\n",
    "# train_dataset = NuscenesDataset()\n",
    "# batch_size = 1\n",
    "# num_epochs = 5\n",
    "# start_training(train_dataset, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'test', 'mini_train', 'mini_val', 'train_detect', 'train_track'])\n"
     ]
    }
   ],
   "source": [
    "from nuscenes.utils.splits import train,val\n",
    "from nuscenes.utils.splits import create_splits_scenes\n",
    "\n",
    "split = create_splits_scenes()\n",
    "print(split.keys())\n",
    "split_scene_list = []\n",
    "for scene_name in split['mini_train']:\n",
    "    for scene in nusc.scene:\n",
    "        if scene['name']==scene_name:\n",
    "            split_scene_list.append(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n",
      "('cc8c0bf57f984915a77078b10eb33198', 'ca9a282c9e77460f8360f564131a8af5')\n"
     ]
    }
   ],
   "source": [
    "#write a sequence \n",
    "\n",
    "sample_dict = {}\n",
    "\n",
    "i = 0 \n",
    "for scene in split_scene_list:\n",
    "    last_sample_token =\"\"\n",
    "    sample_token = scene['first_sample_token']\n",
    "    while(last_sample_token == \"\"):\n",
    "        \n",
    "        sample = nusc.get('sample', sample_token)\n",
    "        sample_dict[i] = (scene['token'],sample[\"token\"])\n",
    "        i += 1\n",
    "        sample_token = sample[\"next\"]\n",
    "        if(sample[\"token\"]== scene['last_sample_token']):\n",
    "            last_sample_token = scene['last_sample_token']\n",
    "\n",
    "print (len(sample_dict))\n",
    "print (sample_dict[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample_key in sample_dict:\n",
    "#     print(sample_dict[sample_key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample_key,sample_value in sample_dict.items():\n",
    "#     print(sample_key, '->', sample_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create List of Graph objects\n",
    "from datasets.nuscenes_mot_graph import NuscenesMotGraph\n",
    "scene_token0, sample_token0= sample_dict[0]\n",
    "\n",
    "MotGraphList= []\n",
    "for sample in sample_dict:\n",
    "    scene_token_current, sample_token_current= sample_dict[0]\n",
    "    if scene_token_current == scene_token0:\n",
    "        object = NuscenesMotGraph(nuscenes_handle = nusc,start_frame=sample_token_current,max_frame_dist = 3)\n",
    "        is_possible2construct = object.is_possible2construct\n",
    "        if is_possible2construct:\n",
    "            object.construct_graph_object()\n",
    "            MotGraphList.append(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.nuscenes_mot_graph.NuscenesMotGraph object at 0x7ff01c5c0c70>\n",
      "----------------------------------------\n",
      "\n",
      "Graph(x=[29, 3], edge_index=[78, 2], edge_attr=[78, 3])\n",
      "----------------------------------------\n",
      "\n",
      "3\n",
      "----------------------------------------\n",
      "\n",
      "['edge_attr', 'edge_index', 'x']\n",
      "----------------------------------------\n",
      "\n",
      "True\n",
      "----------------------------------------\n",
      "\n",
      "False\n",
      "----------------------------------------\n",
      "\n",
      "tensor([[ 3.7352e+01,  6.4397e+01,  4.5099e-01],\n",
      "        [ 9.1482e+00, -1.9542e+01, -1.6450e+00],\n",
      "        [ 5.9793e+00,  3.5009e+01,  4.4059e-02],\n",
      "        [-8.2717e+00,  7.7670e+01,  2.0498e+00],\n",
      "        [ 3.3012e+00,  4.0340e+01,  1.4580e-01],\n",
      "        [ 2.9526e+01,  6.5011e+01,  5.7588e-01],\n",
      "        [ 3.7855e+01,  7.0953e+01,  6.9073e-01],\n",
      "        [-2.0532e+00,  3.8026e+01,  2.7026e-01],\n",
      "        [ 3.7712e+01,  5.9681e+01,  2.0375e+01],\n",
      "        [ 8.5972e+00, -2.8851e+01,  1.7925e+01],\n",
      "        [ 6.2841e+00,  3.1319e+01,  2.0017e+01],\n",
      "        [-7.8481e+00,  7.3213e+01,  2.2176e+01],\n",
      "        [ 3.8192e+00,  4.1440e+01,  2.0297e+01],\n",
      "        [ 2.9870e+01,  6.0342e+01,  2.0508e+01],\n",
      "        [ 3.8358e+01,  6.6223e+01,  2.0803e+01],\n",
      "        [-1.8751e+00,  3.6130e+01,  2.0322e+01],\n",
      "        [ 6.2228e+00,  7.5057e+01,  2.1847e+01],\n",
      "        [ 2.8392e+01,  6.6930e+01,  2.0901e+01],\n",
      "        [ 3.8058e+01,  5.4645e+01,  3.9974e+01],\n",
      "        [ 7.9043e+00, -3.8837e+01,  3.7866e+01],\n",
      "        [ 6.4671e+00,  2.6719e+01,  3.9731e+01],\n",
      "        [-7.4381e+00,  6.8469e+01,  4.1651e+01],\n",
      "        [ 4.4899e+00,  4.2807e+01,  4.0143e+01],\n",
      "        [ 3.0205e+01,  5.5387e+01,  4.0156e+01],\n",
      "        [ 3.8840e+01,  6.1181e+01,  4.0380e+01],\n",
      "        [-1.6937e+00,  3.3990e+01,  4.0054e+01],\n",
      "        [ 6.9196e+00,  7.4192e+01,  4.1400e+01],\n",
      "        [ 4.6840e+01,  6.0988e+01,  4.0355e+01],\n",
      "        [ 2.8802e+01,  6.1951e+01,  4.0501e+01]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MotGraphList[0])\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj)\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(len(MotGraphList[0].graph_obj))\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj.keys)\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj.is_directed())\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj.is_undirected())\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj[\"x\"])\n",
    "print(\"----------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31145/2003269233.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstandard_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMotGraphList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31145/3140897751.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "standard_loader = DataLoader(MotGraphList, batch_size=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "434941593aed7c9146eb321e17df2547a675a0813990b3197c9f49b3135b1bdb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
