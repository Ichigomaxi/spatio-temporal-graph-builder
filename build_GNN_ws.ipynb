{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to build a graph purely with KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 1.164 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='/media/HDD2/Datasets/mini_nusc', verbose=True)\n",
    "\n",
    "# nusc = NuScenes(version='v1.0-trainval', dataroot='/media/HDD2/Datasets/nuscenes2', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/maximilian/.cache/pyg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric as tgeo\n",
    "\n",
    "tgeo.get_home_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get set of scenes\n",
    "scenes = nusc.scene\n",
    "#Get first scenes\n",
    "scene_0 = scenes[0]\n",
    "# Get token of first frame\n",
    "first_sample_token = scene_0['first_sample_token']\n",
    "\n",
    "NUMBER_OF_SKIPPED_FRAMES = 10\n",
    "for i in range(NUMBER_OF_SKIPPED_FRAMES):\n",
    "    temp_sample = nusc.get('sample', first_sample_token)\n",
    "    temp_token = temp_sample['next']\n",
    "    first_sample_token = temp_token\n",
    "\n",
    "sample_0 = nusc.get('sample', first_sample_token)\n",
    "# Get tokens for 2 following frames\n",
    "second_sample_token = sample_0['next']\n",
    "sample_1 = nusc.get('sample', second_sample_token)\n",
    "third_sample_token = sample_1['next']\n",
    "sample_2 = nusc.get('sample', third_sample_token)\n",
    "\n",
    "# Get LIDAR pointcloud\n",
    "sensor = 'LIDAR_TOP'\n",
    "lidar_top_data_0 = nusc.get('sample_data', sample_0['data'][sensor])\n",
    "# Get LIDAR KF pointcloud\n",
    "lidar_top_data_1 = nusc.get('sample_data', sample_1['data'][sensor])\n",
    "# Get LIDAR KF pointcloud\n",
    "lidar_top_data_2 = nusc.get('sample_data', sample_2['data'][sensor])\n",
    "\n",
    "#Filter out car/vehicle object\n",
    "pcl0_path, boxes0, _= nusc.get_sample_data(lidar_top_data_0['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "pcl1_path, boxes1, _= nusc.get_sample_data(lidar_top_data_1['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "pcl2_path, boxes2, _= nusc.get_sample_data(lidar_top_data_2['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get point clouds\n",
    "import os.path as osp\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, Box\n",
    "\n",
    "#Load Pointclouds\n",
    "pc0 = LidarPointCloud.from_file(pcl0_path)\n",
    "pc1 = LidarPointCloud.from_file(pcl1_path)\n",
    "pc2 = LidarPointCloud.from_file(pcl2_path)\n",
    "\n",
    "from utility import get_box_centers, filter_boxes\n",
    "\n",
    "car_boxes_0 = filter_boxes(nusc, boxes = boxes0, categoryQuery= 'vehicle.car')\n",
    "car_boxes_1 = filter_boxes(nusc, boxes = boxes1, categoryQuery= 'vehicle.car')\n",
    "car_boxes_2 = filter_boxes(nusc, boxes = boxes2, categoryQuery= 'vehicle.car')\n",
    "\n",
    "centers0 = get_box_centers(car_boxes_0)\n",
    "centers1 = get_box_centers(car_boxes_1)\n",
    "centers2 = get_box_centers(car_boxes_2)\n",
    "\n",
    "# Special Shift parameter in meter\n",
    "SPATIAL_SHIFT_TIMEFRAMES = 20\n",
    "# Boxes 0 can stay at the current frame\n",
    "# centers0\n",
    "# Boxes 1 must be translated up by l meters\n",
    "centers1 += np.array([0,0,SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# Boxes 2 must be translated up by 2*l meters\n",
    "centers2 += np.array([0,0,2*SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# Add all centroids into one array\n",
    "centers = np.empty((0,3))\n",
    "centers = np.append(centers, centers0, axis=0)\n",
    "centers = np.append(centers, centers1, axis=0)\n",
    "centers = np.append(centers, centers2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build KNN Graph\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from graph.graph_generation import Graph\n",
    "\n",
    "# Add temporal edges / Make connections#####################\n",
    "temporal_pointpairs = []\n",
    "\n",
    "TEMPORAL_KNN_PARAM = 3\n",
    "''' \n",
    "Defines the number of searched neighbors\n",
    "'''\n",
    "\n",
    "# connect frame-0-nodes with frame-1-nodes\n",
    "for i in range(len(centers0)):\n",
    "    center = centers0[i]\n",
    "    center = np.expand_dims(center,axis=0)\n",
    "    temp = np.append(centers1,center,axis=0)\n",
    "    #Find nearest_neigbor\n",
    "    nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "    temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "    #Add indices into a list\n",
    "    for index in temporal_indices[-1]:\n",
    "        #adapt the index to the global indexing\n",
    "        # temporal_pointpairs.append([i, index + len(centers0)])\n",
    "\n",
    "        # find global indices and append them\n",
    "        reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "        neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "        temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "             neighbor_node_global_index ])\n",
    "\n",
    "# connect frame-0-nodes with frame-2-nodes\n",
    "for i in range(len(centers0)):\n",
    "    center = centers0[i]\n",
    "    center = np.expand_dims(center,axis=0)\n",
    "    temp = np.append(centers2,center,axis=0)\n",
    "    #Find nearest_neigbor\n",
    "    nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "    temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "    #Add indices into a list (The last entry belongs to center!)\n",
    "    for index in temporal_indices[-1]:\n",
    "        #adapt the index to the global indexing\n",
    "        # temporal_pointpairs.append([i, index + len(centers0)])\n",
    "\n",
    "        # find global indices and append them\n",
    "        reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "        neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "        temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "             neighbor_node_global_index ])\n",
    "\n",
    "# connect frame-1-nodes with frame-2-nodes\n",
    "for i in range(len(centers1)):\n",
    "    center = centers1[i]\n",
    "    center = np.expand_dims(center,axis=0)\n",
    "    temp = np.append(centers2,center,axis=0)\n",
    "    nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "    temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "\n",
    "    # Test if the last input is the appended center point\n",
    "    # assert (temporal_distances[-1] == temporal_distances[np.argwhere(temp == center)[0,0]]).all()\n",
    "\n",
    "    for index in temporal_indices[-1]:\n",
    "        #adapt the index to the global indexing\n",
    "        # temporal_pointpairs.append([i + len(centers0) , index + len(centers0) + len(centers1) ])\n",
    "        \n",
    "        # find global indices and append them\n",
    "        reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "        neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "        temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "             neighbor_node_global_index ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 2)\n"
     ]
    }
   ],
   "source": [
    "#Build graph in a more organised manner\n",
    "from graph.graph_generation import SpatioTemporalGraph, Timeframe\n",
    "\n",
    "SPATIAL_NEIGHBOR_NUMS = 5\n",
    "\n",
    "nbrs_0 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers0)\n",
    "# Frame t0\n",
    "#Compute K nearest neighbors\n",
    "spatial_distances_0, spatial_indices_0 = nbrs_0.kneighbors(centers0)\n",
    "# Make a list of tuple pairs\n",
    "spatial_pairs = [] \n",
    "for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_0):\n",
    "    for neigbor_index in neigborhood_indices:\n",
    "        spatial_pairs.append( \\\n",
    "            ( (Timeframe.t0,curr_node_idx) , ((Timeframe.t0,neigbor_index)) ) )\n",
    "\n",
    "#Frame t1\n",
    "nbrs_1 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers1)\n",
    "spatial_distances_1, spatial_indices_1 = nbrs_1.kneighbors(centers1)\n",
    "# Make a list of tuple pairs\n",
    "for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_1):\n",
    "    for neigbor_index in neigborhood_indices:\n",
    "        spatial_pairs.append( \\\n",
    "            ( (Timeframe.t1,curr_node_idx) , ((Timeframe.t1,neigbor_index)) ) )\n",
    "\n",
    "#Frame t2\n",
    "nbrs_2 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers2)\n",
    "spatial_distances_2, spatial_indices_2 = nbrs_2.kneighbors(centers2)\n",
    "# Make a list of tuple pairs\n",
    "for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_2):\n",
    "    for neigbor_index in neigborhood_indices:\n",
    "        spatial_pairs.append( \\\n",
    "            ( (Timeframe.t2,curr_node_idx) , ((Timeframe.t2,neigbor_index)) ) )\n",
    "\n",
    "testgraph = SpatioTemporalGraph(spatial_pairs)\n",
    "\n",
    "# Get all spatial Edges\n",
    "spatial_pointpairs0 = []\n",
    "for reference_node in testgraph._graph:\n",
    "    if(reference_node[0]== Timeframe.t0):\n",
    "        for neighbor_node in testgraph._graph[reference_node]:\n",
    "            # print(neighbor_index[0])\n",
    "            timestep, idx = neighbor_node[0],neighbor_node[1]\n",
    "            if timestep == Timeframe.t0:\n",
    "                spatial_pointpairs0.append([reference_node[1],idx])\n",
    "\n",
    "print(np.shape(spatial_pointpairs0))\n",
    "testarray = testgraph.get_spatial_pointpairs(Timeframe.t0)\n",
    "assert spatial_pointpairs0 == testarray\n",
    "\n",
    "spatial_pointpairs1 = testgraph.get_spatial_pointpairs(Timeframe.t1)\n",
    "spatial_pointpairs2 = testgraph.get_spatial_pointpairs(Timeframe.t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 33\n"
     ]
    }
   ],
   "source": [
    "# Generate  Flow Labels for TrackingGNN\n",
    "from groundtruth_generation.nuscenes_create_gt import generate_flow_labels\n",
    "from utils.nuscenes_helper_functions import is_valid_box\n",
    "\n",
    "car_boxes = [] \n",
    "for list in [car_boxes_0, car_boxes_1, car_boxes_2]:\n",
    "    for box in list:\n",
    "        car_boxes.append(box)\n",
    "\n",
    "if len(car_boxes)== len(centers):\n",
    "    print('length', len(car_boxes))\n",
    "    # for box, center in zip(car_boxes, centers):\n",
    "    for i in range(len(car_boxes)):\n",
    "        box, center = car_boxes[i], centers[i]\n",
    "        if not is_valid_box(box, center, num_frames = 3, spatial_shift_timeframes=SPATIAL_SHIFT_TIMEFRAMES):\n",
    "            print('invalid boxes at ',i)\n",
    "            print('box',box.center)\n",
    "            print('center',center)\n",
    "\n",
    "flow_labels = generate_flow_labels(nusc,temporal_pointpairs, car_boxes, centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_list = []\n",
    "spatio_temporal_edge_indices = temporal_pointpairs \\\n",
    "        + spatial_pointpairs0\n",
    "data_list.append(Data(x= centers,edge_index= spatio_temporal_edge_indices, y= flow_labels))\n",
    "loader = DataLoader(data_list, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "434941593aed7c9146eb321e17df2547a675a0813990b3197c9f49b3135b1bdb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
