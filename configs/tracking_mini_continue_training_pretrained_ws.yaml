# Config for naming logging directory
run_id: 'train_mini_continuation_default_config'
add_date: True
cross_val_split: 

# Config for logging directory path
output_path : '/media/HDD2/students/maximilian/spatio-temporal-gnn'

# Config to load previous model
load_checkpoint : True # Set to true to load a previous checkpoint
overwrite_saved_hparam: False # Set to true to if you want to use new hyperparameters(Defined in this config file) 
# ckpt_path: 'experiments/path_/to/_checkpoint.ckpt'
ckpt_path: 'experiments/05-03_20:07_train_w_default_config/checkpoints/epoch=12-step=86878.ckpt' # Only used during evaluation 

# Config for modes from the nuscenes split
train_dataset_mode: "mini_train"
eval_dataset_mode: "mini_val"

gpu_settings:
  device_type: "gpu"
  # Specify which GPUs to use
  device_id: [1] # Specifically takes the gpu associated with cuda:1 
  torch_device: 'cuda:1'

train_params:
  batch_size: 4
  num_epochs: 400
  optimizer:
    type: Adam
    args:
      lr: 0.001
      weight_decay: 0.0001

  lr_scheduler:
    type:
    args:
      step_size: 7
      gamma: 0.5

  num_workers: 0 # Used for dataloaders
  save_every_epoch: True # Determines if every a checkpoint will be saved for every epoch
  save_epoch_start: 1 # If the arg above is set to True, determines the first epoch after which we start saving ckpts
  tensorboard: True
  include_custom_checkpointing : True

dataset_params:
  # Preprocessing ParamsL
  load_valid_sequence_sample_list : True
  # If the above is true then specify the path to the pickle files
  # Must be absolutepath until now
  # if mode not train or val then sequence_sample_list_train_path will be loaded into Dataset object
  sequence_sample_list_train_path : '/media/HDD2/students/maximilian/spatio-temporal-gnn/dataset/preprocess_dataset_mini_nuscenes/sequence_sample_list_mini_train.pkl'
  sequence_sample_list_val_path : '/media/HDD2/students/maximilian/spatio-temporal-gnn/dataset/preprocess_dataset_mini_nuscenes/sequence_sample_list_mini_val.pkl'
  
  # Dataset Processing params:
  dataset_version: 'v1.0-trainval'
  dataroot : '/media/HDD2/Datasets/mini_nusc'
  is_windows_path : True
  # Edge_Label Type
  label_type: "binary"

  # Filter Parameter
  # Contains a list of nuscenes class labels.
  # Only detections from these clases will be loaded for the graph
  filterBoxes_categoryQuery: ['vehicle.car'] 

  # Data Augmentation Params
  augment: False # Determines whether data augmentation is performed

  # Graph Construction Parameters
  max_frame_dist: 3 # Maximum number of frames contained in each graph sampled graph
  node_feature_mode : "centers_and_time" # determines the included node features 
  edge_feature_mode : "edge_type" # determines the included edge features 

  # Choose how Graph construction should be handled
  adapt_knn_param: False # if number of objects is below the KNN-Param then K

data_splits: # See nuscenes.datasplit()
  train: ['scene-0061', 'scene-0553', 'scene-0655', 'scene-0757', 'scene-0796', 'scene-1077', 'scene-1094', 'scene-1100']
  val: ['scene-0103', 'scene-0916']
  test: []

eval_params:
  # Logging / Metrics reporting params
  tensorboard: True

graph_model_params:
  node_agg_fn: 'sum'
  num_enc_steps: 12  # Number of message passing steps
  num_class_steps: 8  # Number of message passing steps during feature vectors are classified (after Message Passing)
  reattach_initial_nodes: False  # Determines whether initially encoded node feats are used during node updates
  reattach_initial_edges: True  # Determines whether initially encoded edge feats are used during node updates

  encoder_feats_dict:
      edge_in_dim: 2
      edge_fc_dims: [18, 18]
      edge_out_dim: 2
      node_in_dim: 4
      #node_fc_dims: [512, 128]
      node_fc_dims: [128]
      node_out_dim: 4
      dropout_p: 0
      use_batchnorm: False
  
  edge_model_feats_dict:
    # Input size is 1(=node_factor) * 2 * #encoded nodes ('node_out_dim') 
    # + 2(=edge_factor) * #encoded edges (edge_out_dim)
    # Make sure last layer's output dimensions 
    # equal the encoded edge feature size
    fc_dims: [80, 2] 
    dropout_p: 0
    use_batchnorm: False

  node_model_feats_dict:
    # In size is 1(=node_factor) * encoded nodes('node_out_dim') 
    # + 1 * encoded edges (edge_out_dim)
    # Make sure last layer's output dimensions 
    # equal the encoded node feature size
    fc_dims: [56, 4]
    dropout_p: 0
    use_batchnorm: False

  # only classifies edges 
  classifier_feats_dict:
    # edge input must be same output/last layer of edge model, edge_model_feats_dict[fc_dims][-1]
    edge_in_dim: 2
    edge_fc_dims: [8]
    edge_out_dim: 1 # only 1 output for binary classification
    dropout_p: 0
    use_batchnorm: False
