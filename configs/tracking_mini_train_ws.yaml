gpu_settings:
  device_type: "gpu"
  # Specify which GPUs to use
  device_id: [1] # Specifically takes the gpu associated with cuda:1 
  torch_device: 'cuda:1'

ckpt_path:

train_params:
  batch_size: 8
  num_epochs: 400
  optimizer:
    type: Adam
    args:
      lr: 0.001
      weight_decay: 0.0001

  lr_scheduler:
    type:
    args:
      step_size: 7
      gamma: 0.5

  num_workers: 4 # Used for dataloaders
  save_every_epoch: False # Determines if every a checkpoint will be saved for every epoch
  save_epoch_start: 1 # If the arg above is set to True, determines the first epoch after which we start saving ckpts
  tensorboard: True

dataset_params:
  # Dataset Processing params:
  dataset_version: 'v1.0-trainval'
  dataroot : '/media/HDD2/Datasets/mini_nusc'
  is_windows_path : True
  # Edge_Label Type
  label_type: "binary"

  # Filter Parameter
  # Contains a list of nuscenes class labels.
  # Only detections from these clases will be loaded for the graph
  filterBoxes_categoryQuery: ['vehicle.car'] 

  # Data Augmentation Params
  augment: False # Determines whether data augmentation is performed

  # Graph Construction Parameters
  max_frame_dist: 3 # Maximum number of frames contained in each graph sampled graph
  node_feature_mode : "centers_and_time" # determines the included node features 
  edge_feature_mode : "edge_type" # determines the included edge features 

data_splits: # See nuscenes.datasplit()
  train: ['scene-0061', 'scene-0553', 'scene-0655', 'scene-0757', 'scene-0796', 'scene-1077', 'scene-1094', 'scene-1100']
  val: ['scene-0103', 'scene-0916']
  test: []

eval_params:
  # Logging / Metrics reporting params
  tensorboard: True

graph_model_params:
  node_agg_fn: 'sum'
  num_enc_steps: 12  # Number of message passing steps
  num_class_steps: 8  # Number of message passing steps during feature vectors are classified (after Message Passing)
  reattach_initial_nodes: False  # Determines whether initially encoded node feats are used during node updates
  reattach_initial_edges: True  # Determines whether initially encoded edge feats are used during node updates

  encoder_feats_dict:
      edge_in_dim: 2
      edge_fc_dims: [18, 18]
      edge_out_dim: 2
      node_in_dim: 4
      #node_fc_dims: [512, 128]
      node_fc_dims: [128]
      node_out_dim: 4
      dropout_p: 0
      use_batchnorm: False
  
  edge_model_feats_dict:
    # Input size is 1(=node_factor) * 2 * #encoded nodes ('node_out_dim') 
    # + 2(=edge_factor) * #encoded edges (edge_out_dim)
    # Make sure last layer's output dimensions 
    # equal the encoded edge feature size
    fc_dims: [80, 2] 
    dropout_p: 0
    use_batchnorm: False

  node_model_feats_dict:
    # In size is 1(=node_factor) * encoded nodes('node_out_dim') 
    # + 1 * encoded edges (edge_out_dim)
    # Make sure last layer's output dimensions 
    # equal the encoded node feature size
    fc_dims: [56, 4]
    dropout_p: 0
    use_batchnorm: False

  # only classifies edges 
  classifier_feats_dict:
    # edge input must be same output/last layer of edge model, edge_model_feats_dict[fc_dims][-1]
    edge_in_dim: 2
    edge_fc_dims: [8]
    edge_out_dim: 1 # only 1 output for binary classification
    dropout_p: 0
    use_batchnorm: False
