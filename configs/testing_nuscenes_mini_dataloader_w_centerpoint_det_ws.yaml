gpu_settings:
  device_type: "gpu"
  # Specify which GPUs to use
  device_id: [1] # Specifically takes the gpu associated with cuda:1 
  torch_device: 'cpu'

# train_dataset_mode: "train"
# eval_dataset_mode: "val"
test_dataset_mode: "mini_val"

dataset_params:
  # Preprocessing Params
  filter_for_buildable_sample_frames: False
  load_valid_sequence_sample_list : False
  # If the above is true then specify the path to the pickle files
  # Must be absolutepath until now
  # if mode not train or val then sequence_sample_list_train_path will be loaded into Dataset object
  sequence_sample_list_train_path : #'/media/HDD2/students/maximilian/spatio-temporal-gnn/dataset/preprocess_dataset_nuscenes/sequence_sample_list_train.pkl' 
  sequence_sample_list_val_path : #'/media/HDD2/students/maximilian/spatio-temporal-gnn/dataset/preprocess_dataset_nuscenes/sequence_sample_list_val.pkl'

  # Dataset Processing params:
  dataset_version: 'v1.0-mini'
  dataroot : '/media/HDD2/Datasets/mini_nusc'
  is_windows_path : False

  # Detection Params:
  use_gt_detections: False # If True loaded detections will equal the sample_annotations from the trainval-set 
  # Path to 3D detections file used for val/test. Must be defined if use_gt_detections==True
  # det_file_path: "/media/HDD2/Datasets/nuscenes_EagerMOT_detections/centerpoint_3Ddetections/val/infos_val_10sweeps_withvelo_filter_True.json"
  det_file_path: "/media/HDD2/Datasets/nuscenes_CBMOT_detections/resources/infos_val_10sweeps_withvelo_filter_True.json"

  # Filter Parameter
  # Contains a list of nuscenes class labels.
  # Only detections from these clases will be loaded for the graph
  # filterBoxes_categoryQuery: ['vehicle.car'] 
  filterBoxes_categoryQuery: ['vehicle.car', 'vehicle.bicycle','vehicle.bus', 'vehicle.motorcycle','human.pedestrian', 'vehicle.trailer', 'vehicle.truck']

  # Graph Construction Parameters
  graph_construction_params:
    spatial_knn_num_neighbors: 4
    temporal_knn_num_neighbors : 4
    spatial_shift_timeframes : 20
    
  max_frame_dist: 6 # Maximum number of frames contained in each graph sampled graph
  # Node Features
  node_feature_mode : "centers_and_time" # determines the included node features 
  # Edge Features
  edge_feature_mode : "edge_type" # determines the included edge features 
  # Edge_Label Type
  label_type: "binary" # "binary" or "multiclass"
  # Choose how Graph construction should be handled
  adapt_knn_param: True # if number of objects is below the KNN-Param then K

  # Data Augmentation Params
  augment: False # Determines whether data augmentation is performed


data_splits: # See nuscenes.datasplit()
  # train: ['scene-0061', 'scene-0553', 'scene-0655', 'scene-0757', 'scene-0796', 'scene-1077', 'scene-1094', 'scene-1100']
  # val: ['scene-0103', 'scene-0916']
  # test: []

eval_params:
  # Logging / Metrics reporting params
  tensorboard: True

graph_model_params:
  node_agg_fn: 'sum'
  num_enc_steps: 5  # Number of message passing steps
  num_class_steps: 3  # Number of message passing steps during feature vectors are classified (after Message Passing)
  reattach_initial_nodes: False  # Determines whether initially encoded node feats are used during node updates
  reattach_initial_edges: True  # Determines whether initially encoded edge feats are used during node updates

  encoder_feats_dict:
      edge_in_dim: 2
      edge_fc_dims: [18, 18]
      edge_out_dim: 2
      node_in_dim: 4
      #node_fc_dims: [512, 128]
      node_fc_dims: [128]
      node_out_dim: 4
      dropout_p: 0
      use_batchnorm: False
  
  edge_model_feats_dict:
    # Input size is 1(=node_factor) * 2 * #encoded nodes ('node_out_dim') 
    # + 2(=edge_factor) * #encoded edges (edge_out_dim)
    # Make sure last layer's output dimensions 
    # equal the encoded edge feature size
    fc_dims: [80, 2] 
    dropout_p: 0
    use_batchnorm: False

  node_model_feats_dict:
    # In size is 1(=node_factor) * encoded nodes('node_out_dim') 
    # + 1 * encoded edges (edge_out_dim)
    # Make sure last layer's output dimensions 
    # equal the encoded node feature size
    fc_dims: [56, 4]
    dropout_p: 0
    use_batchnorm: False

  # only classifies edges 
  classifier_feats_dict:
    # edge input must be same output/last layer of edge model, edge_model_feats_dict[fc_dims][-1]
    edge_in_dim: 2
    edge_fc_dims: [8]
    edge_out_dim: 1 # only 1 output for binary classification
    dropout_p: 0
    use_batchnorm: False
