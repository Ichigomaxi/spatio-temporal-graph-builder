{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.core.fromnumeric import shape\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 0.646 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='/home/max/projects/masterthesis/mini_nuscenes', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get set of scenes\n",
    "scenes = nusc.scene\n",
    "#Get first scenes\n",
    "scene_0 = scenes[0]\n",
    "# Get token of first frame\n",
    "first_sample_token = scene_0['first_sample_token']\n",
    "sample_0 = nusc.get('sample', first_sample_token)\n",
    "# Get tokens for 2 following frames\n",
    "second_sample_token = sample_0['next']\n",
    "sample_1 = nusc.get('sample', second_sample_token)\n",
    "third_sample_token = sample_1['next']\n",
    "sample_2 = nusc.get('sample', third_sample_token)\n",
    "\n",
    "# Get LIDAR pointcloud\n",
    "sensor = 'LIDAR_TOP'\n",
    "lidar_top_data_0 = nusc.get('sample_data', sample_0['data'][sensor])\n",
    "# Get LIDAR KF pointcloud\n",
    "lidar_top_data_1 = nusc.get('sample_data', sample_1['data'][sensor])\n",
    "# Get LIDAR KF pointcloud\n",
    "lidar_top_data_2 = nusc.get('sample_data', sample_2['data'][sensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out car/vehicle object\n",
    "pcl0_path, boxes0, _= nusc.get_sample_data(lidar_top_data_0['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "pcl1_path, boxes1, _= nusc.get_sample_data(lidar_top_data_1['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "pcl2_path, boxes2, _= nusc.get_sample_data(lidar_top_data_2['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get point clouds\n",
    "import os.path as osp\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, Box\n",
    "\n",
    "# pcl0_path = osp.join(nusc.dataroot, lidar_top_data_0['filename'])\n",
    "# pcl1_path = osp.join(nusc.dataroot, lidar_top_data_1['filename'])\n",
    "# pcl2_path = osp.join(nusc.dataroot, lidar_top_data_2['filename'])\n",
    "#Load Pointclouds\n",
    "pc0 = LidarPointCloud.from_file(pcl0_path)\n",
    "pc1 = LidarPointCloud.from_file(pcl1_path)\n",
    "pc2 = LidarPointCloud.from_file(pcl2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category stats for split v1.0-mini:\n",
      "human.pedestrian.adult      n= 4765, width= 0.68±0.11, len= 0.73±0.17, height= 1.76±0.12, lw_aspect= 1.08±0.23\n",
      "human.pedestrian.child      n=   46, width= 0.46±0.08, len= 0.45±0.09, height= 1.37±0.06, lw_aspect= 0.97±0.05\n",
      "human.pedestrian.constructi n=  193, width= 0.69±0.07, len= 0.74±0.12, height= 1.78±0.05, lw_aspect= 1.07±0.16\n",
      "human.pedestrian.personal_m n=   25, width= 0.83±0.00, len= 1.28±0.00, height= 1.87±0.00, lw_aspect= 1.55±0.00\n",
      "human.pedestrian.police_off n=   11, width= 0.59±0.00, len= 0.47±0.00, height= 1.81±0.00, lw_aspect= 0.80±0.00\n",
      "movable_object.barrier      n= 2323, width= 2.32±0.49, len= 0.61±0.11, height= 1.06±0.10, lw_aspect= 0.28±0.09\n",
      "movable_object.debris       n=   13, width= 0.43±0.00, len= 1.43±0.00, height= 0.46±0.00, lw_aspect= 3.35±0.00\n",
      "movable_object.pushable_pul n=   82, width= 0.51±0.06, len= 0.79±0.10, height= 1.04±0.20, lw_aspect= 1.55±0.18\n",
      "movable_object.trafficcone  n= 1378, width= 0.47±0.14, len= 0.45±0.07, height= 0.78±0.13, lw_aspect= 0.99±0.12\n",
      "static_object.bicycle_rack  n=   54, width= 2.67±1.46, len=10.09±6.19, height= 1.40±0.00, lw_aspect= 5.97±4.02\n",
      "vehicle.bicycle             n=  243, width= 0.64±0.12, len= 1.82±0.14, height= 1.39±0.34, lw_aspect= 2.94±0.41\n",
      "vehicle.bus.bendy           n=   57, width= 2.83±0.09, len= 9.23±0.33, height= 3.32±0.07, lw_aspect= 3.27±0.22\n",
      "vehicle.bus.rigid           n=  353, width= 2.95±0.26, len=11.46±1.79, height= 3.80±0.62, lw_aspect= 3.88±0.57\n",
      "vehicle.car                 n= 7619, width= 1.92±0.16, len= 4.62±0.36, height= 1.69±0.21, lw_aspect= 2.41±0.18\n",
      "vehicle.construction        n=  196, width= 2.58±0.35, len= 5.57±1.57, height= 2.38±0.33, lw_aspect= 2.18±0.62\n",
      "vehicle.motorcycle          n=  471, width= 0.68±0.21, len= 1.95±0.38, height= 1.47±0.20, lw_aspect= 3.00±0.62\n",
      "vehicle.trailer             n=   60, width= 2.28±0.08, len=10.14±5.69, height= 3.71±0.27, lw_aspect= 4.37±2.41\n",
      "vehicle.truck               n=  649, width= 2.35±0.34, len= 6.50±1.56, height= 2.62±0.68, lw_aspect= 2.75±0.37\n"
     ]
    }
   ],
   "source": [
    "nusc.list_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle.car\n",
      "vehicle.car\n"
     ]
    }
   ],
   "source": [
    "category = nusc.get('sample_annotation',boxes0[16].token)['category_name']\n",
    "print(category)\n",
    "if( category.find('vehicle') != -1 ):\n",
    "    print(category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (13,) \n",
      " List:\n",
      " ['924ee6ac1fed440a9d9e3720aac635a0', '36d52dfedd764b27863375543c965376', '63b89fe17f3e41ecbe28337e0e35db8e', '16140fbf143d4e26a4a7613cbd3aa0e8', '83d881a6b3d94ef3a3bc3b585cc514f8', '74986f1604f047b6925d409915265bf7', '076a7e3ec6244d3b84e7df5ebcbac637', 'cda0a9085607438c9b1ea87f4360dd64', 'a6f7d4bb60374f868144c5ba4431bf4c', '91cb8f15ed4444e99470d43515e50c1d', '26fb370c13f844de9d1830f6176ebab6', 'b7cbc6d0e80e4dfda7164871ece6cb71', '49f76277d07541c5a584aa14c9d28754']\n"
     ]
    }
   ],
   "source": [
    "#Find only vehicle objects for frame 0\n",
    "vehicle_boxes_tokens_0 = []\n",
    "for box in boxes0:\n",
    "    category = nusc.get('sample_annotation',box.token)['category_name']\n",
    "    if( category.find('vehicle') != -1 ):\n",
    "        vehicle_boxes_tokens_0.append(box.token)\n",
    "print('shape:',np.shape(vehicle_boxes_tokens_0),'\\n List:\\n',vehicle_boxes_tokens_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8,) \n",
      " List:\n",
      " ['924ee6ac1fed440a9d9e3720aac635a0', '63b89fe17f3e41ecbe28337e0e35db8e', '16140fbf143d4e26a4a7613cbd3aa0e8', '74986f1604f047b6925d409915265bf7', 'cda0a9085607438c9b1ea87f4360dd64', 'a6f7d4bb60374f868144c5ba4431bf4c', '26fb370c13f844de9d1830f6176ebab6', '49f76277d07541c5a584aa14c9d28754']\n"
     ]
    }
   ],
   "source": [
    "#Find only car objects for frame 0\n",
    "car_boxes_tokens_0 = []\n",
    "car_boxes_0 = []\n",
    "for box in boxes0:\n",
    "    category = nusc.get('sample_annotation',box.token)['category_name']\n",
    "    if( category.find('vehicle.car') != -1 ):\n",
    "        car_boxes_tokens_0.append(box.token)\n",
    "        car_boxes_0.append(box)\n",
    "print('shape:',np.shape(car_boxes_tokens_0),'\\n List:\\n',car_boxes_tokens_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find all car annotations in nuscenes\n",
    "# car_boxes_tokens_all = []\n",
    "# for sample_annotation in nusc.sample_annotation:\n",
    "#     category = sample_annotation['category_name']\n",
    "#     if( category.find('vehicle.car') != -1 ):\n",
    "#         car_boxes_tokens_all.append(sample_annotation[\"token\"])\n",
    "\n",
    "# print('shape:',np.shape(car_boxes_tokens_all),'\\n List:\\n',car_boxes_tokens_all[:5])\n",
    "\n",
    "# # \n",
    "# _, boxes0_car, _= nusc.get_sample_data( lidar_top_data_0['token'], \\\n",
    "#      selected_anntokens=car_boxes_tokens_all, use_flat_vehicle_coordinates =False)\n",
    "\n",
    "# # Not a viable option because it gets all sample annotations and not only the ones of frame 0\n",
    "# print(np.shape(boxes0_car))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import get_box_centers, filter_boxes\n",
    "\n",
    "car_boxes_0 = filter_boxes(nusc, boxes = boxes0, categoryQuery= 'vehicle.car')\n",
    "car_boxes_1 = filter_boxes(nusc, boxes = boxes1, categoryQuery= 'vehicle.car')\n",
    "car_boxes_2 = filter_boxes(nusc, boxes = boxes2, categoryQuery= 'vehicle.car')\n",
    "\n",
    "centers0 = get_box_centers(car_boxes_0)\n",
    "centers1 = get_box_centers(car_boxes_1)\n",
    "centers2 = get_box_centers(car_boxes_2)\n",
    "\n",
    "# Special Shift parameter in meter\n",
    "SPATIAL_SHIFT_TIMEFRAMES = 20\n",
    "# Boxes 0 can stay at the current frame\n",
    "# centers0\n",
    "# Boxes 1 must be translated up by l meters\n",
    "centers1 += np.array([0,0,SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# Boxes 2 must be translated up by 2*l meters\n",
    "centers2 += np.array([0,0,2*SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# Add all centroids into one array\n",
    "centers = np.empty((0,3))\n",
    "centers = np.append(centers, centers0, axis=0)\n",
    "centers = np.append(centers, centers1, axis=0)\n",
    "centers = np.append(centers, centers2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build KNN Graph\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#Build graph in a more organised manner\n",
    "from graph.graph_generation import SpatioTemporalGraph, Timeframe\n",
    "\n",
    "nbrs_0 = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(centers0)\n",
    "# Frame t0\n",
    "#Compute K nearest neighbors\n",
    "spatial_distances_0, spatial_indices_0 = nbrs_0.kneighbors(centers0)\n",
    "# Make a list of tuple pairs\n",
    "spatial_pairs = [] \n",
    "for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_0):\n",
    "    for neigbor_index in neigborhood_indices:\n",
    "        spatial_pairs.append( \\\n",
    "            ( (Timeframe.t0,curr_node_idx) , ((Timeframe.t0,neigbor_index)) ) )\n",
    "\n",
    "#Frame t1\n",
    "nbrs_1 = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(centers1)\n",
    "spatial_distances_1, spatial_indices_1 = nbrs_1.kneighbors(centers1)\n",
    "# Make a list of tuple pairs\n",
    "for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_1):\n",
    "    for neigbor_index in neigborhood_indices:\n",
    "        spatial_pairs.append( \\\n",
    "            ( (Timeframe.t1,curr_node_idx) , ((Timeframe.t1,neigbor_index)) ) )\n",
    "\n",
    "#Frame t2\n",
    "nbrs_2 = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(centers2)\n",
    "spatial_distances_2, spatial_indices_2 = nbrs_2.kneighbors(centers2)\n",
    "# Make a list of tuple pairs\n",
    "for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_2):\n",
    "    for neigbor_index in neigborhood_indices:\n",
    "        spatial_pairs.append( \\\n",
    "            ( (Timeframe.t2,curr_node_idx) , ((Timeframe.t2,neigbor_index)) ) )\n",
    "\n",
    "testgraph = SpatioTemporalGraph(spatial_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2, 2)\n",
      "(18, 2, 2)\n",
      "((<Timeframe.t0: 0>, 0), (<Timeframe.t1: 1>, 0))\n"
     ]
    }
   ],
   "source": [
    "from utility import is_same_instance\n",
    "\n",
    "# Add temporal edges #####################\n",
    "# Only connect unique objects to themselves. Only Connect boxes\n",
    "# that belong to the same object instance and subsequently same class\n",
    "#Initiate graph\n",
    "temporal_pairs = []\n",
    "# Looking for connections between frame i and frame j\n",
    "# Frame 0 ==> Frame 1\n",
    "for i,box_i in enumerate(car_boxes_0):\n",
    "    for j,box_j in enumerate(car_boxes_1):\n",
    "        if is_same_instance(nusc, box_i.token, box_j.token):\n",
    "            temporal_pairs.append( \\\n",
    "                ( (Timeframe.t0,i) , ((Timeframe.t1,j)) ) )\n",
    "print(np.shape(temporal_pairs))\n",
    "# Frame 1 ==> Frame 2\n",
    "for i,box_i in enumerate(car_boxes_1):\n",
    "    for j,box_j in enumerate(car_boxes_2):\n",
    "        if is_same_instance(nusc, box_i.token, box_j.token):\n",
    "            temporal_pairs.append( \\\n",
    "                ( (Timeframe.t1,i) , ((Timeframe.t2,j)) ) )\n",
    "print(np.shape(temporal_pairs))\n",
    "print(temporal_pairs[0])\n",
    "\n",
    "testgraph.add_connections(temporal_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "# Get all spatial Edges\n",
    "spatial_pointpairs0 = []\n",
    "for reference_node in testgraph._graph:\n",
    "    if(reference_node[0]== Timeframe.t0):\n",
    "        for neighbor_node in testgraph._graph[reference_node]:\n",
    "            # print(neighbor_index[0])\n",
    "            timestep, idx = neighbor_node[0],neighbor_node[1]\n",
    "            if timestep == Timeframe.t0:\n",
    "                spatial_pointpairs0.append([reference_node[1],idx])\n",
    "\n",
    "print(np.shape(spatial_pointpairs0))\n",
    "testarray = testgraph.get_spatial_pointpairs(Timeframe.t0)\n",
    "assert spatial_pointpairs0 == testarray\n",
    "\n",
    "spatial_pointpairs1 = testgraph.get_spatial_pointpairs(Timeframe.t1)\n",
    "spatial_pointpairs2 = testgraph.get_spatial_pointpairs(Timeframe.t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n",
      "(10, 3)\n",
      "(11, 3)\n",
      "(29, 3)\n",
      "29\n",
      "7\n",
      "{(<Timeframe.t0: 0>, 0), (<Timeframe.t0: 0>, 6), (<Timeframe.t1: 1>, 0), (<Timeframe.t0: 0>, 2), (<Timeframe.t0: 0>, 5), (<Timeframe.t0: 0>, 4)}\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(centers0))\n",
    "print(np.shape(centers1))\n",
    "print(np.shape(centers2))\n",
    "print(np.shape(centers))\n",
    "print(len(testgraph._graph))\n",
    "print(len(testgraph._graph[(Timeframe.t1, 0)]))\n",
    "print(testgraph._graph[(Timeframe.t0, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Timeframe.t0: 0>, 0)\n",
      "6\n",
      "(<Timeframe.t1: 1>, 0)\n",
      "(<Timeframe.t0: 0>, 6)\n",
      "6\n",
      "(<Timeframe.t1: 1>, 6)\n",
      "(<Timeframe.t0: 0>, 5)\n",
      "9\n",
      "(<Timeframe.t1: 1>, 5)\n",
      "(<Timeframe.t0: 0>, 4)\n",
      "9\n",
      "(<Timeframe.t1: 1>, 4)\n",
      "(<Timeframe.t0: 0>, 2)\n",
      "8\n",
      "(<Timeframe.t1: 1>, 2)\n",
      "(<Timeframe.t0: 0>, 1)\n",
      "6\n",
      "(<Timeframe.t1: 1>, 1)\n",
      "(<Timeframe.t0: 0>, 7)\n",
      "7\n",
      "(<Timeframe.t1: 1>, 7)\n",
      "(<Timeframe.t0: 0>, 3)\n",
      "7\n",
      "(<Timeframe.t1: 1>, 3)\n",
      "(<Timeframe.t1: 1>, 0)\n",
      "7\n",
      "(<Timeframe.t0: 0>, 0)\n",
      "(<Timeframe.t2: 2>, 0)\n",
      "(<Timeframe.t1: 1>, 6)\n",
      "7\n",
      "(<Timeframe.t0: 0>, 6)\n",
      "(<Timeframe.t2: 2>, 6)\n",
      "(<Timeframe.t1: 1>, 5)\n",
      "10\n",
      "(<Timeframe.t2: 2>, 5)\n",
      "(<Timeframe.t0: 0>, 5)\n",
      "(<Timeframe.t1: 1>, 9)\n",
      "8\n",
      "(<Timeframe.t2: 2>, 10)\n",
      "(<Timeframe.t1: 1>, 8)\n",
      "9\n",
      "(<Timeframe.t2: 2>, 8)\n",
      "(<Timeframe.t1: 1>, 1)\n",
      "7\n",
      "(<Timeframe.t2: 2>, 1)\n",
      "(<Timeframe.t0: 0>, 1)\n",
      "(<Timeframe.t1: 1>, 2)\n",
      "8\n",
      "(<Timeframe.t2: 2>, 2)\n",
      "(<Timeframe.t0: 0>, 2)\n",
      "(<Timeframe.t1: 1>, 7)\n",
      "8\n",
      "(<Timeframe.t2: 2>, 7)\n",
      "(<Timeframe.t0: 0>, 7)\n",
      "(<Timeframe.t1: 1>, 4)\n",
      "9\n",
      "(<Timeframe.t2: 2>, 4)\n",
      "(<Timeframe.t0: 0>, 4)\n",
      "(<Timeframe.t1: 1>, 3)\n",
      "7\n",
      "(<Timeframe.t0: 0>, 3)\n",
      "(<Timeframe.t2: 2>, 3)\n",
      "(<Timeframe.t2: 2>, 0)\n",
      "6\n",
      "(<Timeframe.t1: 1>, 0)\n",
      "(<Timeframe.t2: 2>, 6)\n",
      "6\n",
      "(<Timeframe.t1: 1>, 6)\n",
      "(<Timeframe.t2: 2>, 5)\n",
      "11\n",
      "(<Timeframe.t1: 1>, 5)\n",
      "(<Timeframe.t2: 2>, 9)\n",
      "5\n",
      "(<Timeframe.t2: 2>, 10)\n",
      "9\n",
      "(<Timeframe.t1: 1>, 9)\n",
      "(<Timeframe.t2: 2>, 1)\n",
      "6\n",
      "(<Timeframe.t1: 1>, 1)\n",
      "(<Timeframe.t2: 2>, 2)\n",
      "7\n",
      "(<Timeframe.t1: 1>, 2)\n",
      "(<Timeframe.t2: 2>, 7)\n",
      "7\n",
      "(<Timeframe.t1: 1>, 7)\n",
      "(<Timeframe.t2: 2>, 4)\n",
      "8\n",
      "(<Timeframe.t1: 1>, 4)\n",
      "(<Timeframe.t2: 2>, 3)\n",
      "6\n",
      "(<Timeframe.t1: 1>, 3)\n",
      "(<Timeframe.t2: 2>, 8)\n",
      "6\n",
      "(<Timeframe.t1: 1>, 8)\n"
     ]
    }
   ],
   "source": [
    "# Get all temporal edges\n",
    "\n",
    "# Get points \n",
    "def get_points(centers0, centers1 ,centers2, reference_node):\n",
    "    print(reference_node)\n",
    "    if(reference_node[0]== Timeframe.t0):\n",
    "        return centers0[reference_node[1]]\n",
    "    elif (reference_node[0]== Timeframe.t1):\n",
    "        return centers1[reference_node[1]]\n",
    "    elif (reference_node[0]== Timeframe.t2):\n",
    "        return centers2[reference_node[1]]\n",
    "    else:\n",
    "        return AttributeError\n",
    "        \n",
    "# Get all temporal edges (only frame 0->1 and 1->2)\n",
    "# global_center_list = centers.tolist()\n",
    "temporal_pairs_indices = []\n",
    "for reference_node in testgraph._graph:\n",
    "    reference_timeframe = reference_node[0]\n",
    "\n",
    "    # Find corresponding indices in global centers list\n",
    "    point_a = get_points(centers0, centers1 ,centers2,reference_node)\n",
    "    reference_idx_global = np.argwhere(centers == point_a)[0,0]\n",
    "\n",
    "    print(len(testgraph._graph[reference_node]))\n",
    "    for neighbor_node in testgraph._graph[reference_node]:\n",
    "        neighbor_timeframe, neighbor_idx = neighbor_node[0],neighbor_node[1]\n",
    "        if neighbor_timeframe != reference_timeframe:\n",
    "            # Find corresponding indices in global centers list\n",
    "            # Reference Node\n",
    "            point_b = get_points(centers0, centers1 ,centers2,neighbor_node)\n",
    "            neighbor_idx_global = np.argwhere(centers == point_b)[0,0]\n",
    "            #Append global indices into list\n",
    "            temporal_pairs_indices.append([reference_idx_global,neighbor_idx_global])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Shape: (34688, 4)\n",
      "Shape: (34720, 4)\n",
      "Shape: (34720, 4)\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from open3d import geometry\n",
    "\n",
    "############ Parameters\n",
    "upward_shift = SPATIAL_SHIFT_TIMEFRAMES\n",
    "##############\n",
    "\n",
    "# Integrate All Center points in Pointcloud-object not necessary but test\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(centers)\n",
    "\n",
    "# Include Pointcloud of timeframe 0 into visualization \n",
    "pc0_transposed = np.transpose(pc0.points)\n",
    "print(\"Shape:\",np.shape(pc0_transposed))\n",
    "pointcloud0 = o3d.geometry.PointCloud()\n",
    "pointcloud0.points = o3d.utility.Vector3dVector(pc0_transposed[:, :3])\n",
    "#Add some color\n",
    "point_color=(0.5, 0.5, 0.5)\n",
    "points_colors = np.tile(np.array(point_color), (pc0_transposed.shape[0], 1))\n",
    "pointcloud0.colors = o3d.utility.Vector3dVector(points_colors)\n",
    "\n",
    "# Include Pointcloud of timeframe 1 into visualization \n",
    "pc1_transposed = np.transpose(pc1.points)\n",
    "print(\"Shape:\",np.shape(pc1_transposed))\n",
    "pointcloud1 = o3d.geometry.PointCloud()\n",
    "pointcloud1.points = o3d.utility.Vector3dVector(pc1_transposed[:, :3])\n",
    "#Add some color\n",
    "point_color=(0.5, 0.5, 0.5)\n",
    "points_colors = np.tile(np.array(point_color), (pc1_transposed.shape[0], 1))\n",
    "pointcloud1.colors = o3d.utility.Vector3dVector(points_colors)\n",
    "# Translate up to stack the point clouds\n",
    "pointcloud1.translate(np.array([0,0,upward_shift]))\n",
    "\n",
    "# Include Pointcloud of timeframe 2 into visualization \n",
    "pc2_transposed = np.transpose(pc2.points)\n",
    "print(\"Shape:\",np.shape(pc2_transposed))\n",
    "pointcloud2 = o3d.geometry.PointCloud()\n",
    "pointcloud2.points = o3d.utility.Vector3dVector(pc2_transposed[:, :3])\n",
    "#Add some color\n",
    "point_color=(0.5, 0.5, 0.5)\n",
    "points_colors = np.tile(np.array(point_color), (pc2_transposed.shape[0], 1))\n",
    "pointcloud2.colors = o3d.utility.Vector3dVector(points_colors)\n",
    "# Translate up to stack the point clouds\n",
    "pointcloud2.translate(np.array([0,0,upward_shift * 2]))\n",
    "\n",
    "# Include reference frame\n",
    "mesh_frame = geometry.TriangleMesh.create_coordinate_frame(\n",
    "            size=1, origin=[0, 0, 0])  # create coordinate frame\n",
    "\n",
    "# Draw Graph/Edges with Lineset\n",
    "# Spatial Edges Red Edges\n",
    "colors = [[1, 0, 0] for i in range(len(spatial_pointpairs0))]\n",
    "line_set0 = geometry.LineSet(points=o3d.utility.Vector3dVector(centers0),\n",
    "    lines=o3d.utility.Vector2iVector(spatial_pointpairs0),)\n",
    "line_set0.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "colors = [[1, 0, 0] for i in range(len(spatial_pointpairs1))]\n",
    "line_set1 = geometry.LineSet(points=o3d.utility.Vector3dVector(centers1),\n",
    "    lines=o3d.utility.Vector2iVector(spatial_pointpairs1),)\n",
    "line_set1.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "colors = [[1, 0, 0] for i in range(len(spatial_pointpairs2))]\n",
    "line_set2 = geometry.LineSet(points=o3d.utility.Vector3dVector(centers2),\n",
    "    lines=o3d.utility.Vector2iVector(spatial_pointpairs2),)\n",
    "line_set2.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Temporal Edges \n",
    "colors = [[0, 0, 1] for i in range(len(temporal_pairs_indices))]\n",
    "temporal_line_set = geometry.LineSet(points=o3d.utility.Vector3dVector(centers),\n",
    "    lines=o3d.utility.Vector2iVector(temporal_pairs_indices),)\n",
    "temporal_line_set.colors = o3d.utility.Vector3dVector(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_axis = 2\n",
    "bbox_color=(0, 1, 0)\n",
    "\n",
    "line_set_bounding_boxes_0 = []\n",
    "line_set_bounding_boxes_1 = []\n",
    "line_set_bounding_boxes_2 = []\n",
    "\n",
    "for box in car_boxes_0:\n",
    "    center = box.center\n",
    "    dim = box.wlh\n",
    "    yaw = np.zeros(3)\n",
    "    yaw[rot_axis] = box.orientation.angle\n",
    "    rot_mat = o3d.geometry.get_rotation_matrix_from_xyz(yaw)\n",
    "    center[rot_axis] += dim[\n",
    "                rot_axis] / 2  # bottom center to gravity center\n",
    "\n",
    "    box3d = geometry.OrientedBoundingBox(center, rot_mat, dim)\n",
    "\n",
    "    line_set_bounding_box_0 = o3d.geometry.LineSet.create_from_oriented_bounding_box(box3d)\n",
    "    line_set_bounding_box_0.paint_uniform_color(bbox_color)\n",
    "    line_set_bounding_box_0\n",
    "    line_set_bounding_boxes_0.append(line_set_bounding_box_0)\n",
    "\n",
    "for box in car_boxes_1:\n",
    "    center = box.center\n",
    "    dim = box.wlh\n",
    "    yaw = np.zeros(3)\n",
    "    yaw[rot_axis] = box.orientation.angle\n",
    "    rot_mat = o3d.geometry.get_rotation_matrix_from_xyz(yaw)\n",
    "    center[rot_axis] += dim[\n",
    "                rot_axis] / 2  # bottom center to gravity center\n",
    "\n",
    "    box3d = geometry.OrientedBoundingBox(center, rot_mat, dim)\n",
    "\n",
    "    line_set_bounding_box_1 = o3d.geometry.LineSet.create_from_oriented_bounding_box(box3d)\n",
    "    line_set_bounding_box_1.paint_uniform_color(bbox_color)\n",
    "    line_set_bounding_box_1.translate(np.array([0,0,upward_shift]))\n",
    "    line_set_bounding_boxes_1.append(line_set_bounding_box_1)\n",
    "\n",
    "for box in car_boxes_2:\n",
    "    center = box.center\n",
    "    dim = box.wlh\n",
    "    yaw = np.zeros(3)\n",
    "    yaw[rot_axis] = box.orientation.angle\n",
    "    rot_mat = o3d.geometry.get_rotation_matrix_from_xyz(yaw)\n",
    "    center[rot_axis] += dim[\n",
    "                rot_axis] / 2  # bottom center to gravity center\n",
    "\n",
    "    box3d = geometry.OrientedBoundingBox(center, rot_mat, dim)\n",
    "\n",
    "    line_set_bounding_box_2 = o3d.geometry.LineSet.create_from_oriented_bounding_box(box3d)\n",
    "    line_set_bounding_box_2.paint_uniform_color(bbox_color)\n",
    "    line_set_bounding_box_2.translate(np.array([0,0,upward_shift * 2]))\n",
    "    line_set_bounding_boxes_2.append(line_set_bounding_box_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_list = [pcd,mesh_frame,line_set0, \\\n",
    "            line_set1,line_set2,temporal_line_set,\\\n",
    "            pointcloud0,pointcloud1, pointcloud2]\n",
    "geometry_list += line_set_bounding_boxes_0\n",
    "geometry_list += line_set_bounding_boxes_1\n",
    "geometry_list += line_set_bounding_boxes_2\n",
    "\n",
    "o3d.visualization.draw_geometries(geometry_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([line_set_bounding_boxes_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "434941593aed7c9146eb321e17df2547a675a0813990b3197c9f49b3135b1bdb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nuscenes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
