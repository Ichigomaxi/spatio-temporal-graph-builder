{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to build a graph purely with KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 2.189 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.3 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "# nusc = NuScenes(version='v1.0-trainval', dataroot='/media/HDD2/Datasets/mini_nusc', verbose=True)\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot=r\"C:\\Users\\maxil\\Documents\\projects\\master_thesis\\mini_nuscenes\", verbose=True)\n",
    "# nusc = NuScenes(version='v1.0-trainval', dataroot='/media/HDD2/Datasets/nuscenes2', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\maxil\\\\.cache\\\\pyg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric as tgeo\n",
    "\n",
    "tgeo.get_home_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get set of scenes\n",
    "# scenes = nusc.scene\n",
    "# #Get first scenes\n",
    "# scene_0 = scenes[0]\n",
    "# # Get token of first frame\n",
    "# first_sample_token = scene_0['first_sample_token']\n",
    "\n",
    "# NUMBER_OF_SKIPPED_FRAMES = 10\n",
    "# for i in range(NUMBER_OF_SKIPPED_FRAMES):\n",
    "#     temp_sample = nusc.get('sample', first_sample_token)\n",
    "#     temp_token = temp_sample['next']\n",
    "#     first_sample_token = temp_token\n",
    "\n",
    "# sample_0 = nusc.get('sample', first_sample_token)\n",
    "# # Get tokens for 2 following frames\n",
    "# second_sample_token = sample_0['next']\n",
    "# sample_1 = nusc.get('sample', second_sample_token)\n",
    "# third_sample_token = sample_1['next']\n",
    "# sample_2 = nusc.get('sample', third_sample_token)\n",
    "\n",
    "# # Get LIDAR pointcloud\n",
    "# sensor = 'LIDAR_TOP'\n",
    "# lidar_top_data_0 = nusc.get('sample_data', sample_0['data'][sensor])\n",
    "# # Get LIDAR KF pointcloud\n",
    "# lidar_top_data_1 = nusc.get('sample_data', sample_1['data'][sensor])\n",
    "# # Get LIDAR KF pointcloud\n",
    "# lidar_top_data_2 = nusc.get('sample_data', sample_2['data'][sensor])\n",
    "\n",
    "# #Filter out car/vehicle object\n",
    "# pcl0_path, boxes0, _= nusc.get_sample_data(lidar_top_data_0['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "# pcl1_path, boxes1, _= nusc.get_sample_data(lidar_top_data_1['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n",
    "# pcl2_path, boxes2, _= nusc.get_sample_data(lidar_top_data_2['token'], selected_anntokens=None, use_flat_vehicle_coordinates =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get point clouds\n",
    "# import os.path as osp\n",
    "# from nuscenes.utils.data_classes import LidarPointCloud, Box\n",
    "\n",
    "# #Load Pointclouds\n",
    "# pc0 = LidarPointCloud.from_file(pcl0_path)\n",
    "# pc1 = LidarPointCloud.from_file(pcl1_path)\n",
    "# pc2 = LidarPointCloud.from_file(pcl2_path)\n",
    "\n",
    "# from utility import get_box_centers, filter_boxes\n",
    "\n",
    "# car_boxes_0 = filter_boxes(nusc, boxes = boxes0, categoryQuery= 'vehicle.car')\n",
    "# car_boxes_1 = filter_boxes(nusc, boxes = boxes1, categoryQuery= 'vehicle.car')\n",
    "# car_boxes_2 = filter_boxes(nusc, boxes = boxes2, categoryQuery= 'vehicle.car')\n",
    "\n",
    "# centers0 = get_box_centers(car_boxes_0)\n",
    "# centers1 = get_box_centers(car_boxes_1)\n",
    "# centers2 = get_box_centers(car_boxes_2)\n",
    "\n",
    "# # Special Shift parameter in meter\n",
    "# SPATIAL_SHIFT_TIMEFRAMES = 20\n",
    "# # Boxes 0 can stay at the current frame\n",
    "# # centers0\n",
    "# # Boxes 1 must be translated up by l meters\n",
    "# centers1 += np.array([0,0,SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# # Boxes 2 must be translated up by 2*l meters\n",
    "# centers2 += np.array([0,0,2*SPATIAL_SHIFT_TIMEFRAMES])\n",
    "\n",
    "# # Add all centroids into one array\n",
    "# centers = np.empty((0,3))\n",
    "# centers = np.append(centers, centers0, axis=0)\n",
    "# centers = np.append(centers, centers1, axis=0)\n",
    "# centers = np.append(centers, centers2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build KNN Graph\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from graph.graph_generation import Graph\n",
    "\n",
    "# # Add temporal edges / Make connections#####################\n",
    "# temporal_pointpairs = []\n",
    "\n",
    "# TEMPORAL_KNN_PARAM = 3\n",
    "# ''' \n",
    "# Defines the number of searched neighbors\n",
    "# '''\n",
    "\n",
    "# # connect frame-0-nodes with frame-1-nodes\n",
    "# for i in range(len(centers0)):\n",
    "#     center = centers0[i]\n",
    "#     center = np.expand_dims(center,axis=0)\n",
    "#     temp = np.append(centers1,center,axis=0)\n",
    "#     #Find nearest_neigbor\n",
    "#     nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "#     temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "#     #Add indices into a list\n",
    "#     for index in temporal_indices[-1]:\n",
    "#         #adapt the index to the global indexing\n",
    "#         # temporal_pointpairs.append([i, index + len(centers0)])\n",
    "\n",
    "#         # find global indices and append them\n",
    "#         reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "#         neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "#         temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "#              neighbor_node_global_index ])\n",
    "\n",
    "# # connect frame-0-nodes with frame-2-nodes\n",
    "# for i in range(len(centers0)):\n",
    "#     center = centers0[i]\n",
    "#     center = np.expand_dims(center,axis=0)\n",
    "#     temp = np.append(centers2,center,axis=0)\n",
    "#     #Find nearest_neigbor\n",
    "#     nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "#     temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "#     #Add indices into a list (The last entry belongs to center!)\n",
    "#     for index in temporal_indices[-1]:\n",
    "#         #adapt the index to the global indexing\n",
    "#         # temporal_pointpairs.append([i, index + len(centers0)])\n",
    "\n",
    "#         # find global indices and append them\n",
    "#         reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "#         neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "#         temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "#              neighbor_node_global_index ])\n",
    "\n",
    "# # connect frame-1-nodes with frame-2-nodes\n",
    "# for i in range(len(centers1)):\n",
    "#     center = centers1[i]\n",
    "#     center = np.expand_dims(center,axis=0)\n",
    "#     temp = np.append(centers2,center,axis=0)\n",
    "#     nearest_neigbor = NearestNeighbors(n_neighbors=TEMPORAL_KNN_PARAM, algorithm='ball_tree').fit(temp)\n",
    "#     temporal_distances, temporal_indices = nearest_neigbor.kneighbors(temp)\n",
    "\n",
    "#     # Test if the last input is the appended center point\n",
    "#     # assert (temporal_distances[-1] == temporal_distances[np.argwhere(temp == center)[0,0]]).all()\n",
    "\n",
    "#     for index in temporal_indices[-1]:\n",
    "#         #adapt the index to the global indexing\n",
    "#         # temporal_pointpairs.append([i + len(centers0) , index + len(centers0) + len(centers1) ])\n",
    "        \n",
    "#         # find global indices and append them\n",
    "#         reference_node_global_index = np.argwhere(centers == center)[0,0]\n",
    "#         neighbor_node_global_index = np.argwhere(centers == temp[index])[0,0] \n",
    "#         temporal_pointpairs.append([reference_node_global_index ,\\\n",
    "#              neighbor_node_global_index ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Build graph in a more organised manner\n",
    "# from graph.graph_generation import SpatioTemporalGraph, Timeframe\n",
    "\n",
    "# SPATIAL_NEIGHBOR_NUMS = 5\n",
    "\n",
    "# nbrs_0 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers0)\n",
    "# # Frame t0\n",
    "# #Compute K nearest neighbors\n",
    "# spatial_distances_0, spatial_indices_0 = nbrs_0.kneighbors(centers0)\n",
    "# # Make a list of tuple pairs\n",
    "# spatial_pairs = [] \n",
    "# for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_0):\n",
    "#     for neigbor_index in neigborhood_indices:\n",
    "#         spatial_pairs.append( \\\n",
    "#             ( (Timeframe.t0,curr_node_idx) , ((Timeframe.t0,neigbor_index)) ) )\n",
    "\n",
    "# #Frame t1\n",
    "# nbrs_1 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers1)\n",
    "# spatial_distances_1, spatial_indices_1 = nbrs_1.kneighbors(centers1)\n",
    "# # Make a list of tuple pairs\n",
    "# for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_1):\n",
    "#     for neigbor_index in neigborhood_indices:\n",
    "#         spatial_pairs.append( \\\n",
    "#             ( (Timeframe.t1,curr_node_idx) , ((Timeframe.t1,neigbor_index)) ) )\n",
    "\n",
    "# #Frame t2\n",
    "# nbrs_2 = NearestNeighbors(n_neighbors=SPATIAL_NEIGHBOR_NUMS, algorithm='ball_tree').fit(centers2)\n",
    "# spatial_distances_2, spatial_indices_2 = nbrs_2.kneighbors(centers2)\n",
    "# # Make a list of tuple pairs\n",
    "# for curr_node_idx ,neigborhood_indices,  in enumerate(spatial_indices_2):\n",
    "#     for neigbor_index in neigborhood_indices:\n",
    "#         spatial_pairs.append( \\\n",
    "#             ( (Timeframe.t2,curr_node_idx) , ((Timeframe.t2,neigbor_index)) ) )\n",
    "\n",
    "# testgraph = SpatioTemporalGraph(spatial_pairs)\n",
    "\n",
    "# # Get all spatial Edges\n",
    "# spatial_pointpairs0 = []\n",
    "# for reference_node in testgraph._graph:\n",
    "#     if(reference_node[0]== Timeframe.t0):\n",
    "#         for neighbor_node in testgraph._graph[reference_node]:\n",
    "#             # print(neighbor_index[0])\n",
    "#             timestep, idx = neighbor_node[0],neighbor_node[1]\n",
    "#             if timestep == Timeframe.t0:\n",
    "#                 spatial_pointpairs0.append([reference_node[1],idx])\n",
    "\n",
    "# print(np.shape(spatial_pointpairs0))\n",
    "# testarray = testgraph.get_spatial_pointpairs(Timeframe.t0)\n",
    "# assert spatial_pointpairs0 == testarray\n",
    "\n",
    "# spatial_pointpairs1 = testgraph.get_spatial_pointpairs(Timeframe.t1)\n",
    "# spatial_pointpairs2 = testgraph.get_spatial_pointpairs(Timeframe.t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate  Flow Labels for TrackingGNN\n",
    "# from groundtruth_generation.nuscenes_create_gt import generate_flow_labels\n",
    "# from utils.nuscenes_helper_functions import is_valid_box\n",
    "\n",
    "# car_boxes = [] \n",
    "# for list in [car_boxes_0, car_boxes_1, car_boxes_2]:\n",
    "#     for box in list:\n",
    "#         car_boxes.append(box)\n",
    "\n",
    "# if len(car_boxes)== len(centers):\n",
    "#     print('length', len(car_boxes))\n",
    "#     # for box, center in zip(car_boxes, centers):\n",
    "#     for i in range(len(car_boxes)):\n",
    "#         box, center = car_boxes[i], centers[i]\n",
    "#         if not is_valid_box(box, center, num_frames = 3, spatial_shift_timeframes=SPATIAL_SHIFT_TIMEFRAMES):\n",
    "#             print('invalid boxes at ',i)\n",
    "#             print('box',box.center)\n",
    "#             print('center',center)\n",
    "\n",
    "# flow_labels = generate_flow_labels(nusc,temporal_pointpairs, car_boxes, centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.loader import DataLoader\n",
    "# import torch\n",
    "# edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "#                            [1, 0, 2, 1]], dtype=torch.long)\n",
    "# x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "# data = Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create list of Data elements\n",
    "# # \n",
    "# data_list = []\n",
    "# spatio_temporal_edge_indices = temporal_pointpairs \\\n",
    "#         + spatial_pointpairs0\n",
    "\n",
    "# data_list.append(Data(x= centers,edge_index= spatio_temporal_edge_indices, y= flow_labels))\n",
    "\n",
    "# standard_loader = DataLoader(data_list, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train import start_training\n",
    "\n",
    "# batch_size = 1\n",
    "# num_epochs = 5\n",
    "# start_training(standard_loader, batch_size, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model.mot_net'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_684/2606097320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnuscenes_dataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNuscenesDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# train_dataset = NuscenesDataset()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# batch_size = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxil\\Documents\\projects\\master_thesis\\spatio-temporal-graph-builer\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmot_net\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMOTNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model.mot_net'"
     ]
    }
   ],
   "source": [
    "from train import start_training\n",
    "from datasets.nuscenes_dataset import NuscenesDataset\n",
    "\n",
    "# train_dataset = NuscenesDataset()\n",
    "# batch_size = 1\n",
    "# num_epochs = 5\n",
    "# start_training(train_dataset, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'test', 'mini_train', 'mini_val', 'train_detect', 'train_track'])\n"
     ]
    }
   ],
   "source": [
    "from nuscenes.utils.splits import train,val\n",
    "from nuscenes.utils.splits import create_splits_scenes\n",
    "\n",
    "split = create_splits_scenes()\n",
    "print(split.keys())\n",
    "split_scene_list = []\n",
    "for scene_name in split['mini_train']:\n",
    "    for scene in nusc.scene:\n",
    "        if scene['name']==scene_name:\n",
    "            split_scene_list.append(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n",
      "('cc8c0bf57f984915a77078b10eb33198', 'ca9a282c9e77460f8360f564131a8af5')\n",
      "('cc8c0bf57f984915a77078b10eb33198', '39586f9d59004284a7114a68825e8eec')\n",
      "('cc8c0bf57f984915a77078b10eb33198', '356d81f38dd9473ba590f39e266f54e5')\n"
     ]
    }
   ],
   "source": [
    "#write a sequence \n",
    "\n",
    "sample_dict = {}\n",
    "\n",
    "i = 0 \n",
    "for scene in split_scene_list:\n",
    "    last_sample_token =\"\"\n",
    "    sample_token = scene['first_sample_token']\n",
    "    while(last_sample_token == \"\"):\n",
    "        \n",
    "        sample = nusc.get('sample', sample_token)\n",
    "        sample_dict[i] = (scene['token'],sample[\"token\"])\n",
    "        i += 1\n",
    "        sample_token = sample[\"next\"]\n",
    "        if(sample[\"token\"]== scene['last_sample_token']):\n",
    "            last_sample_token = scene['last_sample_token']\n",
    "\n",
    "print (len(sample_dict))\n",
    "print (sample_dict[0])\n",
    "print (sample_dict[1])\n",
    "print (sample_dict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample_key in sample_dict:\n",
    "#     print(sample_dict[sample_key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample_key,sample_value in sample_dict.items():\n",
    "#     print(sample_key, '->', sample_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from enum import Enum\n",
    "# import torch \n",
    "\n",
    "# class edge_label_classes(Enum):\n",
    "#     different_instance = 0\n",
    "#     same_instance = 1\n",
    "#     new_instance = 2\n",
    "\n",
    "# label_one_hot = torch.zeros(len(edge_label_classes), dtype=torch.uint8, device = \"cpu\")\n",
    "# label_one_hot[1] = 1\n",
    "\n",
    "# label_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "\n",
    "# a = range(6)\n",
    "# a = torch.tensor(a).reshape(3,2)\n",
    "# b = a[:,1]\n",
    "# c = a[:,0]\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print(c)\n",
    "# d = torch.stack((b,c),dim = 1)\n",
    "# print(d)\n",
    "# print(d.shape[1])\n",
    "\n",
    "# a = range(6)\n",
    "# a = torch.tensor(a).reshape(2,-1)\n",
    "# b = a[1]\n",
    "# c = a[0]\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print(c)\n",
    "# d = torch.stack((b,c),dim = 0)\n",
    "# print(d)\n",
    "# print(d.shape[1])\n",
    "\n",
    "# d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "2\n",
      "torch.Size([6])\n",
      "final_shape:  torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "#Create List of Graph objects\n",
    "from datasets.nuscenes_mot_graph import NuscenesMotGraph\n",
    "#______________________________________________________________#\n",
    "# Decide if only first scene should be computed\n",
    "only_first_scene = True\n",
    "scene_token0, sample_token0= sample_dict[0]\n",
    "#_______________________________________________________________#\n",
    "\n",
    "MotGraphList= []\n",
    "for sample_key in sample_dict:\n",
    "    scene_token_current, sample_token_current= sample_dict[sample_key]\n",
    "    if(only_first_scene):\n",
    "        if(scene_token0 == scene_token_current):\n",
    "            object = NuscenesMotGraph(nuscenes_handle = nusc,start_frame=sample_token_current,max_frame_dist = 3, filterBoxes_categoryQuery='vehicle.car')\n",
    "            is_possible2construct = object.is_possible2construct\n",
    "            if is_possible2construct:\n",
    "                object.construct_graph_object()\n",
    "                object.assign_edge_labels_one_hot()\n",
    "                MotGraphList.append(object)\n",
    "    else:\n",
    "        object = NuscenesMotGraph(nuscenes_handle = nusc,start_frame=sample_token_current,max_frame_dist = 3,  filterBoxes_categoryQuery='vehicle.car')\n",
    "        is_possible2construct = object.is_possible2construct\n",
    "        if is_possible2construct:\n",
    "            object.construct_graph_object()\n",
    "            object.assign_edge_labels_one_hot()\n",
    "            MotGraphList.append(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "37\n",
      "----------------------------------------\n",
      "\n",
      "<datasets.nuscenes_mot_graph.NuscenesMotGraph object at 0x0000023CDAD64808>\n",
      "----------------------------------------\n",
      "\n",
      "Graph(x=[29, 3], edge_index=[2, 156], edge_attr=[156, 3], edge_labels=[6])\n",
      "----------------------------------------\n",
      "\n",
      "4\n",
      "----------------------------------------\n",
      "\n",
      "['x', 'edge_attr', 'edge_index', 'edge_labels']\n",
      "----------------------------------------\n",
      "\n",
      "is_undirected() :  True\n",
      "----------------------------------------\n",
      "\n",
      "tensor([[ 3.7352e+01,  6.4397e+01,  4.5099e-01],\n",
      "        [ 9.1482e+00, -1.9542e+01, -1.6450e+00],\n",
      "        [ 5.9793e+00,  3.5009e+01,  4.4059e-02],\n",
      "        [-8.2717e+00,  7.7670e+01,  2.0498e+00],\n",
      "        [ 3.3012e+00,  4.0340e+01,  1.4580e-01]], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "\n",
      "tensor([[ 3.7352e+01,  6.4397e+01,  4.5099e-01],\n",
      "        [ 9.1482e+00, -1.9542e+01, -1.6450e+00],\n",
      "        [ 5.9793e+00,  3.5009e+01,  4.4059e-02],\n",
      "        [-8.2717e+00,  7.7670e+01,  2.0498e+00],\n",
      "        [ 3.3012e+00,  4.0340e+01,  1.4580e-01]], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "\n",
      "graph_dataframe[\"boxes_dict\"][1][0] \n",
      " label: nan, score: nan, xyz: [37.71, 59.68, 0.38], wlh: [2.01, 4.63, 1.57], rot axis: [0.01, -0.02, 1.00], ang(degrees): 176.66, ang(rad): 3.08, vel: nan, nan, nan, name: vehicle.car, token: f0cbd9dbafd74e20bcf6dd0357c97f59\n",
      "----------------------------------------\n",
      "\n",
      "box_list: \n",
      " label: nan, score: nan, xyz: [37.71, 59.68, 0.38], wlh: [2.01, 4.63, 1.57], rot axis: [0.01, -0.02, 1.00], ang(degrees): 176.66, ang(rad): 3.08, vel: nan, nan, nan, name: vehicle.car, token: f0cbd9dbafd74e20bcf6dd0357c97f59 center_list: \n",
      " [37.71180139 59.6810415  20.37543913]\n",
      "----------------------------------------\n",
      "\n",
      "is same memory ?: \n",
      " True\n",
      "----------------------------------------\n",
      "\n",
      "label: nan, score: nan, xyz: [37.35, 64.40, 0.45], wlh: [2.01, 4.63, 1.57], rot axis: [0.01, -0.02, 1.00], ang(degrees): 176.99, ang(rad): 3.09, vel: nan, nan, nan, name: vehicle.car, token: 924ee6ac1fed440a9d9e3720aac635a0\n",
      "tensor([37.3519, 64.3973,  0.4510], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "\n",
      "label: nan, score: nan, xyz: [9.15, -19.54, -1.65], wlh: [1.84, 4.32, 1.63], rot axis: [-0.01, -0.02, 1.00], ang(degrees): -97.12, ang(rad): -1.70, vel: nan, nan, nan, name: vehicle.car, token: 63b89fe17f3e41ecbe28337e0e35db8e\n",
      "tensor([  9.1482, -19.5423,  -1.6450], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "\n",
      "label: nan, score: nan, xyz: [5.98, 35.01, 0.04], wlh: [1.71, 4.01, 1.63], rot axis: [-0.03, 0.01, -1.00], ang(degrees): -86.09, ang(rad): -1.50, vel: nan, nan, nan, name: vehicle.car, token: 16140fbf143d4e26a4a7613cbd3aa0e8\n",
      "tensor([ 5.9793, 35.0087,  0.0441], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "label: nan, score: nan, xyz: [37.35, 64.40, 0.45], wlh: [2.01, 4.63, 1.57], rot axis: [0.01, -0.02, 1.00], ang(degrees): 176.99, ang(rad): 3.09, vel: nan, nan, nan, name: vehicle.car, token: 924ee6ac1fed440a9d9e3720aac635a0\n",
      "tensor([37.3519, 64.3973,  0.4510], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "\n",
      "label: nan, score: nan, xyz: [28.80, 61.95, 0.50], wlh: [1.88, 4.36, 1.44], rot axis: [0.01, -0.02, 1.00], ang(degrees): 177.68, ang(rad): 3.10, vel: nan, nan, nan, name: vehicle.car, token: 4be63266852547f8a9c590f7a9641ed4\n",
      "tensor([28.8019, 61.9511, 40.5006], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "\n",
      "label: nan, score: nan, xyz: [46.84, 60.99, 0.36], wlh: [2.02, 5.58, 2.13], rot axis: [0.01, -0.02, 1.00], ang(degrees): 178.37, ang(rad): 3.11, vel: nan, nan, nan, name: vehicle.car, token: 59e05c3569054c7fbe6b50d134560f76\n",
      "tensor([46.8400, 60.9879, 40.3551], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Edge Labels:  tensor([0, 1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------\\n\")\n",
    "print(len(MotGraphList))\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0])\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj)\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(len(MotGraphList[0].graph_obj))\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj.keys)\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(\"is_undirected() : \",MotGraphList[0].graph_obj.is_undirected())\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj[\"x\"][0:5])\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(MotGraphList[0].graph_obj.x[0:5])\n",
    "print(\"----------------------------------------\\n\")\n",
    "print('graph_dataframe[\"boxes_dict\"][1][0] \\n',MotGraphList[0].graph_dataframe[\"boxes_dict\"][1][0])\n",
    "print(\"----------------------------------------\\n\")\n",
    "box_list, center_list = MotGraphList[0].graph_dataframe[\"centers_dict\"][1]\n",
    "print(\"box_list: \\n\",box_list[0], 'center_list: \\n', center_list[0])\n",
    "print(\"----------------------------------------\\n\")\n",
    "box_list, center_list = MotGraphList[0].graph_dataframe[\"centers_dict\"][1]\n",
    "print(\"is same memory ?: \\n\", MotGraphList[0].graph_dataframe[\"boxes_dict\"][1] is box_list )\n",
    "print(\"----------------------------------------\\n\")\n",
    "for i in range(3):\n",
    "    print(MotGraphList[0].graph_dataframe[\"boxes_list_all\"][i] )\n",
    "    print(MotGraphList[0].graph_dataframe[\"centers_list_all\"][i])\n",
    "    print(\"----------------------------------------\\n\")\n",
    "print(\"----------------------------------------\\n\")\n",
    "for i in range(3):\n",
    "    print(MotGraphList[0].graph_dataframe[\"boxes_list_all\"][-i] )\n",
    "    print(MotGraphList[0].graph_dataframe[\"centers_list_all\"][-i])\n",
    "    print(\"----------------------------------------\\n\")\n",
    "print(\"----------------------------------------\\n\")\n",
    "print(\"Edge Labels: \",MotGraphList[0].graph_obj[\"edge_labels\"])\n",
    "print(\"----------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(3, 16)\n",
    "        self.conv2 = GCNConv(16, 2)\n",
    "        self.mlp = torch.nn.Linear(\n",
    "                    in_features=3, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x \n",
    "        edge_index = data.edge_index\n",
    "        edge_feature =data.edge_attr\n",
    "\n",
    "        # x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        x = x.float()\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "[Graph(x=[29, 3], edge_index=[78, 2], edge_attr=[78, 3], edge_labels=[78]), Graph(x=[32, 3], edge_index=[93, 2], edge_attr=[93, 3], edge_labels=[93]), Graph(x=[34, 3], edge_index=[99, 2], edge_attr=[99, 3], edge_labels=[99]), Graph(x=[34, 3], edge_index=[102, 2], edge_attr=[102, 3], edge_labels=[102]), Graph(x=[34, 3], edge_index=[105, 2], edge_attr=[105, 3], edge_labels=[105])]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "graph_list = []\n",
    "for graph in MotGraphList:\n",
    "    graph_list.append(graph.graph_obj)\n",
    "print(len(graph_list))\n",
    "print(graph_list[:5])\n",
    "train_loader = DataLoader(graph_list, batch_size=1,shuffle =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in train_loader:\n",
    "    # print(data.x)\n",
    "    # print(data.edge_index)\n",
    "    # print(data.edge_attr)\n",
    "    # print(data.num_graphs)\n",
    "\n",
    "# a = torch.zeros(3,5).to('cuda')\n",
    "# probabilities_labels = torch.empty(a.shape).uniform_(0, 1).to('cuda')\n",
    "# label = torch.bernoulli(probabilities_labels).to('cuda')\n",
    "# print(a)\n",
    "# print(probabilities_labels)\n",
    "# print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "False\n",
      "<torch_geometric.loader.dataloader.DataLoader object at 0x000001B7ADB68988>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  50%|█████     | 2/4 [00:00<00:00,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss_general: 6.665434663360183\n",
      "epoch 1 loss_general: 1.8820655136495024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████| 4/4 [00:00<00:00, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss_general: 1.0705142665553737\n",
      "epoch 3 loss_general: 0.7233479280729551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def train():\n",
    "#     model.train()\n",
    "\n",
    "#     loss_all = 0\n",
    "#     for data in train_loader:\n",
    "#         data = data.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         label = data.y.to(device)\n",
    "#         loss = crit(output, label)\n",
    "#         loss.backward()\n",
    "#         loss_all += data.num_graphs * loss.item()\n",
    "#         optimizer.step()\n",
    "#     return loss_all / len(graph_list)\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = Net().to(device)\n",
    "print(next(model.parameters()).is_cuda)\n",
    "# print(model.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "crit = torch.nn.BCELoss()\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "loss_general = []\n",
    "for epoch in tqdm(range(4),desc=\"epoch\"):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #Generate random labels for testing pipeline\n",
    "        # generate binary labels \n",
    "        probabilities_labels = torch.empty(output.shape).uniform_(0, 1).to(device)\n",
    "        node_labels_binary = torch.bernoulli(probabilities_labels)\n",
    "        loss = crit(output, node_labels_binary)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    loss_normalized =loss_all / len(graph_list)\n",
    "    loss_general.append(loss_normalized)\n",
    "    print('epoch',epoch,'loss_general:',loss_normalized)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "434941593aed7c9146eb321e17df2547a675a0813990b3197c9f49b3135b1bdb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
